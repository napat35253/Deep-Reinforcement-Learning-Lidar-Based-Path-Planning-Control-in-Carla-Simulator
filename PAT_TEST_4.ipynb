{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "try:\n",
    "    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "import carla\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "#import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "SECONDS_PER_EPISODE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xxx():\n",
    "    env.world.wait_for_tick()\n",
    "    for x in list(env.world.get_actors()):\n",
    "        if x.type_id == 'vehicle.tesla.model3' or x.type_id == 'sensor.lidar.ray_cast' or x.type_id == 'sensor.other.collision':\n",
    "            x.destroy()\n",
    "            \n",
    "def lidar_line(points,degree,width):\n",
    "    angle = degree*(2*np.pi)/360\n",
    "    points_l = points\n",
    "    points_l = points_l[np.logical_and(points_l[:,2] > -1.75, points_l[:,2] < 1000)] #z\n",
    "    points_l = points_l[np.logical_and(np.tan(angle)*points_l[:,0]+width*np.sqrt(1+np.tan(angle)**2)>=points_l[:,1], np.tan(angle)*points_l[:,0]-width*np.sqrt(1+np.tan(angle)**2)<=points_l[:,1])] #y\n",
    "    if 180>degree >0:\n",
    "        points_l = points_l[np.logical_and(points_l[:,1]>0, points_l[:,1]<1000)] #y>0\n",
    "    if 180<degree<360:\n",
    "        points_l = points_l[np.logical_and(points_l[:,1]<0, points_l[:,1] > -1000)] #x\n",
    "    if degree == 0 or degree == 360:\n",
    "        points_l = points_l[np.logical_and(points_l[:,0]>0,points_l[:,0] <1000 )] #x\n",
    "    if degree == 180:\n",
    "        points_l = points_l[np.logical_and(points_l[:,0] >-1000 , points_l[:,0]<0 )]\n",
    "    return  points_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarEnv:\n",
    "    #BRAKE_AMT = 1.0\n",
    "    actor_list = []\n",
    "    collision_hist = []\n",
    "    pt_cloud = []\n",
    "    pt_cloud_filtered = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = carla.Client('localhost', 2000)\n",
    "        self.client.set_timeout(2.0)\n",
    "        self.world = self.client.get_world()\n",
    "        blueprint_library = self.world.get_blueprint_library()\n",
    "        self.model_3 = blueprint_library.filter('model3')[0]\n",
    "        self.truck_2 = blueprint_library.filter('carlamotors')[0]\n",
    "        #settings = self.world.get_settings()\n",
    "        #settings.no_rendering_mode = True\n",
    "        #self.world.apply_settings(settings)\n",
    "                     \n",
    "    def reset(self):\n",
    "        self.collision_hist = []\n",
    "        self.actor_list = []\n",
    "        self.pt_cloud = []\n",
    "        self.pt_cloud_filtered = []\n",
    "        place=random.uniform(110,150)\n",
    "        ##print('Location: ',str(place))\n",
    "        #transform = carla.Transform(carla.Location(-120,place,3),carla.Rotation(0,-90,0))\n",
    "        transform = carla.Transform(carla.Location(246,-36,3),carla.Rotation(0,-90,0))        \n",
    "        self.flag = 0\n",
    "        self.vehicle = self.world.spawn_actor(self.model_3, transform)\n",
    "        self.flag = 1\n",
    "        \n",
    "        self.actor_list.append(self.vehicle)\n",
    "\n",
    "        self.lidar_sensor = self.world.get_blueprint_library().find('sensor.lidar.ray_cast')\n",
    "        self.lidar_sensor.set_attribute('points_per_second', '100000')\n",
    "        self.lidar_sensor.set_attribute('channels', '32')\n",
    "        self.lidar_sensor.set_attribute('range', '10000')\n",
    "        self.lidar_sensor.set_attribute('upper_fov', '10')\n",
    "        self.lidar_sensor.set_attribute('lower_fov', '-10')\n",
    "        self.lidar_sensor.set_attribute('rotation_frequency', '60')\n",
    "\n",
    "        transform = carla.Transform(carla.Location(x=0, z=1.9))\n",
    "        self.sensor = self.world.spawn_actor(self.lidar_sensor, transform, attach_to=self.vehicle)\n",
    "\n",
    "        self.actor_list.append(self.sensor)\n",
    "        self.sensor.listen(lambda data: self.process_lidar(data))\n",
    "\n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=1, brake=0.0))\n",
    "        self.episode_start = time.time()\n",
    "\n",
    "        time.sleep(0.4) # sleep to get things started and to not detect a collision when the car spawns/falls from sky.\n",
    "        \n",
    "        transform2 = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "        colsensor = self.world.get_blueprint_library().find('sensor.other.collision')\n",
    "        self.colsensor = self.world.spawn_actor(colsensor, transform2, attach_to=self.vehicle)\n",
    "        self.actor_list.append(self.colsensor)\n",
    "        self.colsensor.listen(lambda event: self.collision_data(event))\n",
    "\n",
    "        while self.distance_to_obstacle_f is None:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        self.episode_start = time.time()\n",
    "\n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=1, brake=0.0))\n",
    "        xx = self.distance_to_obstacle_f\n",
    "        yy = self.distance_to_obstacle_r\n",
    "        zz = self.distance_to_obstacle_l\n",
    "        \n",
    "        state_=np.array([xx,yy,zz])\n",
    "        return state_\n",
    "\n",
    "    def collision_data(self, event):\n",
    "        self.collision_hist.append(event)\n",
    "\n",
    "    def process_lidar(self, raw):\n",
    "        points = np.frombuffer(raw.raw_data, dtype=np.dtype('f4'))\n",
    "        points = np.reshape(points, (int(points.shape[0] / 3), 3))*np.array([1,-1,-1])\n",
    "        \n",
    "        lidar_f = lidar_line(points,90,2)\n",
    "        lidar_r = lidar_line(points,45,2)\n",
    "        lidar_l = lidar_line(points,135,2)\n",
    "\n",
    "        if len(lidar_f) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            self.distance_to_obstacle_f = min(lidar_f[:,1])-2.247148275375366\n",
    "        \n",
    "        if len(lidar_r) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            self.distance_to_obstacle_r = np.sqrt(min(lidar_r[:,0]**2 + lidar_r[:,1]**2))\n",
    "        \n",
    "        if len(lidar_l) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            self.distance_to_obstacle_l = np.sqrt(min(lidar_l[:,0]**2 + lidar_l[:,1]**2))\n",
    "    \n",
    "\n",
    "    def step(self, action):\n",
    "        sleepy=0.1\n",
    "        if action == 0:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, brake=0.0, steer = 0.3))\n",
    "            time.sleep(sleepy)\n",
    "            reward = 0.1\n",
    "        elif action == 1:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, brake=0.0, steer = -0.3))\n",
    "            time.sleep(sleepy)\n",
    "            reward =0.1\n",
    "\n",
    "        \n",
    "        if len(self.collision_hist) != 0:\n",
    "            done = True\n",
    "            reward = -10\n",
    "        else :\n",
    "            done=False\n",
    "            reward=0.01\n",
    "            \n",
    "        if self.episode_start + SECONDS_PER_EPISODE < time.time():\n",
    "            done = True\n",
    "            \n",
    "        xx = self.distance_to_obstacle_f\n",
    "        yy = self.distance_to_obstacle_r\n",
    "        zz = self.distance_to_obstacle_l\n",
    "        state_=np.array([xx,yy,zz])\n",
    "            \n",
    "        return state_, reward, done, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, state_size, action_size, batch_size):\n",
    "        self.state_size    = state_size\n",
    "        self.action_size   = action_size\n",
    "        self.batch_size    = batch_size\n",
    "        self.memory        = deque(maxlen=2000)\n",
    "        self.gamma         = 0.95   # discount rate\n",
    "        self.epsilon       = 1.0    # exploration rate\n",
    "        self.epsilon_min   = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.dqn           = self.build_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        dqn = Sequential()\n",
    "        dqn.add(Dense(24, input_dim=self.state_size, activation='tanh')) # input dimension = #states\n",
    "        dqn.add(Dense(self.action_size, activation='linear'))            # output nodes = #action\n",
    "        dqn.compile(loss='mse', optimizer=Adam(lr=0.01))                      \n",
    "        print(dqn.summary())\n",
    "        return dqn\n",
    "\n",
    "    def act(self, state, explore):\n",
    "        if explore and np.random.rand() <= self.epsilon: # explore/exploit tradeoff\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.dqn.predict(state)\n",
    "        return np.argmax(act_values[0]) \n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def train(self):\n",
    "        if len(self.memory)<self.batch_size:\n",
    "            return\n",
    "\n",
    "        X, dqnY = [], []\n",
    "        minibatch = random.sample(self.memory, self.batch_size) \n",
    "\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            X.append( state[0] )\n",
    "            target = reward if done else reward + self.gamma * np.max(self.dqn.predict(next_state)[0])\n",
    "            target_dqn = self.dqn.predict(state)\n",
    "            target_dqn[0][action] = target\n",
    "            dqnY.append( target_dqn[0] )\n",
    "\n",
    "\n",
    "        self.dqn.train_on_batch( np.array(X), np.array(dqnY) )\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:    # gradually change from explore to exploit\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 actions, 3-dim state\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 24)                96        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 146\n",
      "Trainable params: 146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "episode: 0/5000, action: 9, e: 1.0\n",
      "episode: 1/5000, action: 6, e: 1.0\n",
      "episode: 2/5000, action: 5, e: 1.0\n",
      "episode: 3/5000, action: 6, e: 1.0\n",
      "episode: 4/5000, action: 7, e: 1.0\n",
      "episode: 5/5000, action: 11, e: 1.0\n",
      "episode: 6/5000, action: 7, e: 1.0\n",
      "episode: 7/5000, action: 8, e: 1.0\n",
      "episode: 8/5000, action: 8, e: 1.0\n",
      "episode: 9/5000, action: 7, e: 1.0\n",
      "episode: 10/5000, action: 7, e: 1.0\n",
      "episode: 11/5000, action: 7, e: 1.0\n",
      "episode: 12/5000, action: 5, e: 1.0\n",
      "episode: 13/5000, action: 7, e: 1.0\n",
      "episode: 14/5000, action: 10, e: 1.0\n",
      "episode: 15/5000, action: 8, e: 1.0\n",
      "episode: 16/5000, action: 5, e: 1.0\n",
      "episode: 17/5000, action: 6, e: 1.0\n",
      "episode: 18/5000, action: 11, e: 1.0\n",
      "episode: 19/5000, action: 119, e: 1.0\n",
      "episode: 20/5000, action: 7, e: 1.0\n",
      "episode: 21/5000, action: 7, e: 1.0\n",
      "episode: 22/5000, action: 6, e: 1.0\n",
      "episode: 23/5000, action: 9, e: 1.0\n",
      "episode: 24/5000, action: 10, e: 1.0\n",
      "episode: 25/5000, action: 16, e: 1.0\n",
      "episode: 26/5000, action: 10, e: 1.0\n",
      "episode: 27/5000, action: 10, e: 1.0\n",
      "episode: 28/5000, action: 7, e: 1.0\n",
      "episode: 29/5000, action: 7, e: 1.0\n",
      "episode: 30/5000, action: 6, e: 1.0\n",
      "episode: 31/5000, action: 7, e: 1.0\n",
      "episode: 32/5000, action: 8, e: 1.0\n",
      "episode: 33/5000, action: 6, e: 1.0\n",
      "episode: 34/5000, action: 9, e: 1.0\n",
      "episode: 35/5000, action: 14, e: 1.0\n",
      "episode: 36/5000, action: 8, e: 1.0\n",
      "episode: 37/5000, action: 7, e: 1.0\n",
      "episode: 38/5000, action: 10, e: 1.0\n",
      "episode: 39/5000, action: 6, e: 1.0\n",
      "episode: 40/5000, action: 6, e: 1.0\n",
      "episode: 41/5000, action: 8, e: 1.0\n",
      "episode: 42/5000, action: 10, e: 1.0\n",
      "episode: 43/5000, action: 6, e: 1.0\n",
      "episode: 44/5000, action: 12, e: 1.0\n",
      "episode: 45/5000, action: 8, e: 1.0\n",
      "episode: 46/5000, action: 6, e: 1.0\n",
      "episode: 47/5000, action: 8, e: 1.0\n",
      "episode: 48/5000, action: 5, e: 1.0\n",
      "episode: 49/5000, action: 10, e: 1.0\n",
      "episode: 50/5000, action: 119, e: 1.0\n",
      "episode: 51/5000, action: 9, e: 1.0\n",
      "episode: 52/5000, action: 5, e: 1.0\n",
      "episode: 53/5000, action: 9, e: 1.0\n",
      "episode: 54/5000, action: 9, e: 1.0\n",
      "episode: 55/5000, action: 9, e: 1.0\n",
      "episode: 56/5000, action: 6, e: 1.0\n",
      "episode: 57/5000, action: 12, e: 1.0\n",
      "episode: 58/5000, action: 6, e: 1.0\n",
      "episode: 59/5000, action: 8, e: 1.0\n",
      "episode: 60/5000, action: 6, e: 1.0\n",
      "episode: 61/5000, action: 5, e: 1.0\n",
      "episode: 62/5000, action: 5, e: 1.0\n",
      "episode: 63/5000, action: 7, e: 1.0\n",
      "episode: 64/5000, action: 15, e: 1.0\n",
      "episode: 65/5000, action: 9, e: 1.0\n",
      "episode: 66/5000, action: 5, e: 1.0\n",
      "episode: 67/5000, action: 5, e: 1.0\n",
      "episode: 68/5000, action: 7, e: 1.0\n",
      "episode: 69/5000, action: 9, e: 1.0\n",
      "episode: 70/5000, action: 6, e: 1.0\n",
      "episode: 71/5000, action: 18, e: 1.0\n",
      "episode: 72/5000, action: 6, e: 1.0\n",
      "episode: 73/5000, action: 8, e: 1.0\n",
      "episode: 74/5000, action: 10, e: 1.0\n",
      "episode: 75/5000, action: 6, e: 1.0\n",
      "episode: 76/5000, action: 6, e: 1.0\n",
      "episode: 77/5000, action: 6, e: 1.0\n",
      "episode: 78/5000, action: 6, e: 1.0\n",
      "episode: 79/5000, action: 7, e: 1.0\n",
      "episode: 80/5000, action: 12, e: 1.0\n",
      "episode: 81/5000, action: 9, e: 1.0\n",
      "episode: 82/5000, action: 9, e: 1.0\n",
      "episode: 83/5000, action: 10, e: 1.0\n",
      "episode: 84/5000, action: 6, e: 1.0\n",
      "episode: 85/5000, action: 11, e: 1.0\n",
      "episode: 86/5000, action: 12, e: 1.0\n",
      "episode: 87/5000, action: 7, e: 1.0\n",
      "episode: 88/5000, action: 13, e: 1.0\n",
      "episode: 89/5000, action: 11, e: 1.0\n",
      "episode: 90/5000, action: 6, e: 1.0\n",
      "episode: 91/5000, action: 6, e: 1.0\n",
      "episode: 92/5000, action: 7, e: 1.0\n",
      "episode: 93/5000, action: 10, e: 1.0\n",
      "episode: 94/5000, action: 8, e: 1.0\n",
      "episode: 95/5000, action: 10, e: 1.0\n",
      "episode: 96/5000, action: 8, e: 1.0\n",
      "episode: 97/5000, action: 10, e: 1.0\n",
      "episode: 98/5000, action: 6, e: 1.0\n",
      "episode: 99/5000, action: 9, e: 1.0\n",
      "episode: 100/5000, action: 14, e: 1.0\n",
      "episode: 101/5000, action: 9, e: 1.0\n",
      "episode: 102/5000, action: 8, e: 1.0\n",
      "episode: 103/5000, action: 5, e: 1.0\n",
      "episode: 104/5000, action: 8, e: 1.0\n",
      "episode: 105/5000, action: 6, e: 1.0\n",
      "episode: 106/5000, action: 9, e: 1.0\n",
      "episode: 107/5000, action: 10, e: 1.0\n",
      "episode: 108/5000, action: 12, e: 1.0\n",
      "episode: 109/5000, action: 10, e: 1.0\n",
      "episode: 110/5000, action: 9, e: 1.0\n",
      "episode: 111/5000, action: 7, e: 1.0\n",
      "episode: 112/5000, action: 14, e: 1.0\n",
      "episode: 113/5000, action: 6, e: 1.0\n",
      "episode: 114/5000, action: 6, e: 1.0\n",
      "episode: 115/5000, action: 7, e: 1.0\n",
      "episode: 116/5000, action: 8, e: 1.0\n",
      "episode: 117/5000, action: 7, e: 1.0\n",
      "episode: 118/5000, action: 9, e: 1.0\n",
      "episode: 119/5000, action: 6, e: 1.0\n",
      "episode: 120/5000, action: 6, e: 1.0\n",
      "episode: 121/5000, action: 9, e: 1.0\n",
      "episode: 122/5000, action: 6, e: 1.0\n",
      "episode: 123/5000, action: 10, e: 1.0\n",
      "episode: 124/5000, action: 7, e: 1.0\n",
      "episode: 125/5000, action: 5, e: 1.0\n",
      "episode: 126/5000, action: 11, e: 1.0\n",
      "episode: 127/5000, action: 11, e: 1.0\n",
      "episode: 128/5000, action: 7, e: 1.0\n",
      "episode: 129/5000, action: 6, e: 1.0\n",
      "episode: 130/5000, action: 12, e: 1.0\n",
      "episode: 131/5000, action: 7, e: 1.0\n",
      "episode: 132/5000, action: 22, e: 1.0\n",
      "episode: 133/5000, action: 12, e: 1.0\n",
      "episode: 134/5000, action: 12, e: 1.0\n",
      "episode: 135/5000, action: 9, e: 1.0\n",
      "episode: 136/5000, action: 10, e: 1.0\n",
      "episode: 137/5000, action: 8, e: 1.0\n",
      "episode: 138/5000, action: 8, e: 1.0\n",
      "episode: 139/5000, action: 10, e: 1.0\n",
      "episode: 140/5000, action: 17, e: 1.0\n",
      "episode: 141/5000, action: 8, e: 1.0\n",
      "episode: 142/5000, action: 9, e: 1.0\n",
      "episode: 143/5000, action: 11, e: 1.0\n",
      "episode: 144/5000, action: 11, e: 1.0\n",
      "episode: 145/5000, action: 7, e: 1.0\n",
      "episode: 146/5000, action: 16, e: 1.0\n",
      "episode: 147/5000, action: 6, e: 1.0\n",
      "episode: 148/5000, action: 5, e: 1.0\n",
      "episode: 149/5000, action: 9, e: 1.0\n",
      "episode: 150/5000, action: 8, e: 1.0\n",
      "episode: 151/5000, action: 6, e: 1.0\n",
      "episode: 152/5000, action: 8, e: 1.0\n",
      "episode: 153/5000, action: 11, e: 1.0\n",
      "episode: 154/5000, action: 9, e: 1.0\n",
      "episode: 155/5000, action: 7, e: 1.0\n",
      "episode: 156/5000, action: 9, e: 1.0\n",
      "episode: 157/5000, action: 8, e: 1.0\n",
      "episode: 158/5000, action: 8, e: 1.0\n",
      "episode: 159/5000, action: 8, e: 1.0\n",
      "episode: 160/5000, action: 10, e: 1.0\n",
      "episode: 161/5000, action: 10, e: 1.0\n",
      "episode: 162/5000, action: 5, e: 1.0\n",
      "episode: 163/5000, action: 10, e: 1.0\n",
      "episode: 164/5000, action: 6, e: 1.0\n",
      "episode: 165/5000, action: 9, e: 1.0\n",
      "episode: 166/5000, action: 10, e: 1.0\n",
      "episode: 167/5000, action: 13, e: 1.0\n",
      "episode: 168/5000, action: 8, e: 1.0\n",
      "episode: 169/5000, action: 14, e: 1.0\n",
      "episode: 170/5000, action: 7, e: 1.0\n",
      "episode: 171/5000, action: 7, e: 1.0\n",
      "episode: 172/5000, action: 9, e: 1.0\n",
      "episode: 173/5000, action: 6, e: 1.0\n",
      "episode: 174/5000, action: 10, e: 1.0\n",
      "episode: 175/5000, action: 6, e: 1.0\n",
      "episode: 176/5000, action: 10, e: 1.0\n",
      "episode: 177/5000, action: 11, e: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-027c9f8c8906>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                 \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-12e2b7497ddb>\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepisode_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# sleep to get things started and to not detect a collision when the car spawns/falls from sky.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mtransform2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcarla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcarla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLocation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    env = CarEnv()\n",
    "    state_size = 3\n",
    "    action_size = 2\n",
    "    print(\"{} actions, {}-dim state\".format(action_size, state_size))\n",
    "    agent = Agent(state_size, action_size, 32)\n",
    "    \n",
    "    emax = 5000\n",
    "    for e in range(emax):\n",
    "        while True:\n",
    "            try:\n",
    "                state = env.reset()\n",
    "                state = state.reshape((1, state_size))\n",
    "                if env.flag == 1:\n",
    "                    break\n",
    "            except RuntimeError as err:\n",
    "                RuntimeError_count += 1\n",
    "                print(err,' ',1)\n",
    "                while True:\n",
    "                    try:\n",
    "                        time.sleep(15)  #wait for 15 sec\n",
    "                        env.client = carla.Client('localhost', 2000) #reconnect to server\n",
    "                        env.client.set_timeout(10.0)\n",
    "                        env.world = env.client.get_world()  #if cannot reconnect, this line will cause an error ---> jump to the 'except' line\n",
    "                        blueprint_library = env.world.get_blueprint_library()\n",
    "                        env.model_3 = blueprint_library.filter('model3')[0]\n",
    "                        for actor in env.actor_list:\n",
    "                            actor.destroy()\n",
    "                        break\n",
    "                    except RuntimeError as err:\n",
    "                        RuntimeError_count += 1\n",
    "                        print(err,' ',RuntimeError_count)\n",
    "    \n",
    "        \n",
    "        for i in range(200):\n",
    "            action = agent.act(state, True)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = next_state.reshape( (1,state_size) )\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            if done:\n",
    "                print(\"episode: {}/{}, action: {}, e: {:.2}\".format(e, emax, i, agent.epsilon))\n",
    "                for actor in env.actor_list:\n",
    "                    actor.destroy()\n",
    "                break\n",
    "        #agent.train()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
