{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import smrclib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "SECONDS_PER_EPISODE = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xxx():\n",
    "    for actor in env.actor_list:\n",
    "        actor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q(state,new_state,action,reward):\n",
    "    global learning_rate,discount_rate,q_table,dist_q\n",
    "    if state == new_state:\n",
    "        if state in dist_q  :\n",
    "            st = dist_q.index(state)\n",
    "            new_st = dist_q.index(new_state)        \n",
    "            q_table[st][action] = q_table[st][action] * (1 - learning_rate) + \\\n",
    "                learning_rate * (reward + discount_rate * max(q_table[new_st][:]))\n",
    "        else :\n",
    "            dist_q.append(state)\n",
    "            dist_q.sort()\n",
    "            st = dist_q.index(state)\n",
    "            new_st = dist_q.index(new_state)\n",
    "            q_table.insert(st,[0,0])\n",
    "            q_table[st][action] = q_table[st][action] * (1 - learning_rate) + \\\n",
    "            learning_rate * (reward + discount_rate * max(q_table[new_st][:]))\n",
    "    else:\n",
    "        if state in dist_q and new_state in dist_q :\n",
    "            st = dist_q.index(state)\n",
    "            new_st = dist_q.index(new_state)\n",
    "            q_table[st][action] = q_table[st][action] * (1 - learning_rate) + \\\n",
    "                learning_rate * (reward + discount_rate * max(q_table[new_st][:]))\n",
    "        elif state in dist_q :\n",
    "            dist_q.append(new_state)\n",
    "            dist_q.sort()\n",
    "            st = dist_q.index(state)\n",
    "            new_st = dist_q.index(new_state)\n",
    "            q_table.insert(new_st,[0,0])\n",
    "            q_table[st][action] = q_table[st][action] * (1 - learning_rate) + \\\n",
    "                learning_rate * (reward + discount_rate * max(q_table[new_st][:]))\n",
    "        elif new_state in dist_q:\n",
    "            dist_q.append(state)\n",
    "            dist_q.sort()\n",
    "            st = dist_q.index(state)\n",
    "            new_st = dist_q.index(new_state)\n",
    "            q_table.insert(st,[0,0])\n",
    "            q_table[st][action] = q_table[st][action] * (1 - learning_rate) + \\\n",
    "                learning_rate * (reward + discount_rate * max(q_table[new_st][:]))\n",
    "        else :\n",
    "            dist_q.append(state)\n",
    "            dist_q.append(new_state)\n",
    "            dist_q.sort()\n",
    "            st = dist_q.index(state)\n",
    "            new_st = dist_q.index(new_state)\n",
    "            q_table.insert(st,[0,0])\n",
    "            q_table.insert(new_st,[0,0])\n",
    "            q_table[st][action] = q_table[st][action] * (1 - learning_rate) + \\\n",
    "                learning_rate * (reward + discount_rate * max(q_table[new_st][:]))\n",
    "            print('NONE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarEnv:\n",
    "    #BRAKE_AMT = 1.0\n",
    "\n",
    "    actor_list = []\n",
    "    collision_hist = []\n",
    "\n",
    "    pt_cloud = []\n",
    "    pt_cloud_filtered = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = carla.Client('localhost', 2000)\n",
    "        self.client.set_timeout(2.0)\n",
    "\n",
    "        self.world = self.client.get_world()\n",
    "\n",
    "        blueprint_library = self.world.get_blueprint_library()\n",
    "\n",
    "        self.model_3 = blueprint_library.filter('model3')[0]\n",
    "        self.truck_2 = blueprint_library.filter('carlamotors')[0]\n",
    "        \n",
    "    def reset(self):\n",
    "        self.collision_hist = []\n",
    "        self.actor_list = []\n",
    "        self.pt_cloud = []\n",
    "        self.pt_cloud_filtered = []\n",
    "        #place=random.uniform(110,150)\n",
    "        ##print('Location: ',str(place))\n",
    "        transform = carla.Transform(carla.Location(-120,125,3),carla.Rotation(0,-90,0))\n",
    "\n",
    "        self.vehicle = self.world.spawn_actor(self.model_3, transform)\n",
    "        \n",
    "        self.actor_list.append(self.vehicle)\n",
    "\n",
    "        self.lidar_sensor = self.world.get_blueprint_library().find('sensor.lidar.ray_cast')\n",
    "        self.lidar_sensor.set_attribute('points_per_second', '100000')\n",
    "        self.lidar_sensor.set_attribute('channels', '32')\n",
    "        self.lidar_sensor.set_attribute('range', '10000')\n",
    "        self.lidar_sensor.set_attribute('upper_fov', '10')\n",
    "        self.lidar_sensor.set_attribute('lower_fov', '-10')\n",
    "        self.lidar_sensor.set_attribute('rotation_frequency', '60')\n",
    "\n",
    "        transform = carla.Transform(carla.Location(x=0, z=1.9))\n",
    "        self.sensor = self.world.spawn_actor(self.lidar_sensor, transform, attach_to=self.vehicle)\n",
    "\n",
    "        self.actor_list.append(self.sensor)\n",
    "        self.sensor.listen(lambda data: self.process_lidar(data))\n",
    "\n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=1, brake=0.0))\n",
    "        self.episode_start = time.time()\n",
    "\n",
    "\n",
    "        time.sleep(4) # sleep to get things started and to not detect a collision when the car spawns/falls from sky.\n",
    "        \n",
    "        transform2 = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "        colsensor = self.world.get_blueprint_library().find('sensor.other.collision')\n",
    "        self.colsensor = self.world.spawn_actor(colsensor, transform2, attach_to=self.vehicle)\n",
    "        self.actor_list.append(self.colsensor)\n",
    "        self.colsensor.listen(lambda event: self.collision_data(event))\n",
    "\n",
    "        while self.distance_to_obstacle is None:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        self.episode_start = time.time()\n",
    "\n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=1, brake=0.0))\n",
    "        \n",
    "        return abs(float(\"%.1f\" % self.distance_to_obstacle))\n",
    "\n",
    "    def collision_data(self, event):\n",
    "        self.collision_hist.append(event)\n",
    "\n",
    "    def process_lidar(self, raw):\n",
    "        points = np.frombuffer(raw.raw_data, dtype=np.dtype('f4'))\n",
    "        points = np.reshape(points, (int(points.shape[0] / 3), 3))*np.array([1,-1,-1])\n",
    "        lidar_data = points.astype(np.int32)\n",
    "        self.pt_cloud.append(lidar_data)\n",
    "\n",
    "        #screen points specifically -4<y<4 and 0<x<12\n",
    "        pt = points[np.logical_and(points[:,0] > -3, points[:,0] < 3)]\n",
    "        points_filter = pt[np.logical_and(pt[:,1] > 0, pt[:,1] < 50)]\n",
    "        points_filter = points_filter[np.logical_and(points_filter[:,1] > 0, points_filter[:,1] < 50)]\n",
    "        self.pt_cloud_filtered.append(points_filter)\n",
    "\n",
    "        if len(points_filter) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            self.distance_to_obstacle = min(points_filter[:,1])-2.247148275375366\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        v = self.vehicle.get_velocity()\n",
    "        kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "        \n",
    "        if action == 0:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, brake=0.0, steer = 0.0))\n",
    "        elif action == 1:\n",
    "            while kmh != 0:\n",
    "                self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=1.0, steer = 0.0))\n",
    "                ##print(kmh)\n",
    "                v = self.vehicle.get_velocity()\n",
    "                kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "                ##print(\"distance_to_obstacle = \",self.distance_to_obstacle)\n",
    "                \n",
    "        # ถ้ารถชน หรือ รถหยุดแล้ว\n",
    "        if kmh == 0 or len(self.collision_hist) != 0 :\n",
    "            done = True\n",
    "            print('DISTANCE FOR REWARD : ',str(self.distance_to_obstacle))\n",
    "            if  0<= self.distance_to_obstacle <1 and len(self.collision_hist) != 0 :\n",
    "                reward = -1\n",
    "            elif  0<= self.distance_to_obstacle <1:\n",
    "                reward = 1\n",
    "            elif  1<= self.distance_to_obstacle <2:\n",
    "                reward = 1.5\n",
    "            elif  2<= self.distance_to_obstacle <3:\n",
    "                reward = 0.45\n",
    "            elif  3<= self.distance_to_obstacle <4:\n",
    "                reward = 0.32\n",
    "            elif  4<= self.distance_to_obstacle <5:\n",
    "                reward = 0.20\n",
    "            elif  5<= self.distance_to_obstacle <6:\n",
    "                reward = -0.15\n",
    "            elif  6<= self.distance_to_obstacle <7:\n",
    "                reward = -0.8\n",
    "            elif  7<= self.distance_to_obstacle <8:\n",
    "                reward = -1.5\n",
    "            elif  8<= self.distance_to_obstacle :\n",
    "                reward = -3\n",
    "        else:\n",
    "            done = False\n",
    "            reward = 0.5\n",
    "        \n",
    "        if self.episode_start + SECONDS_PER_EPISODE < time.time():\n",
    "            done = True\n",
    "            reward = -1\n",
    "            dist = 0\n",
    "            \n",
    "        dist=abs(float(\"%.1f\" % self.distance_to_obstacle))\n",
    "            \n",
    "\n",
    "        return dist,reward, done, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.780643701553345\n",
      "NONE\n",
      "[[ 0.    0.  ]\n",
      " [ 0.   -0.08]]\n",
      "episode number =  1\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.894084215164185\n",
      "[[ 0.     0.   ]\n",
      " [ 0.     0.   ]\n",
      " [ 0.    -0.152]]\n",
      "episode number =  2\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.844031572341919\n",
      "[[ 0.     0.   ]\n",
      " [ 0.     0.   ]\n",
      " [ 0.    -0.152]\n",
      " [ 0.05  -0.08 ]]\n",
      "episode number =  3\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.796159982681274\n",
      "[[ 0.     0.   ]\n",
      " [ 0.     0.   ]\n",
      " [ 0.    -0.152]\n",
      " [ 0.    -0.08 ]\n",
      " [ 0.05  -0.08 ]]\n",
      "episode number =  4\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.80236554145813\n",
      "[[ 0.       0.     ]\n",
      " [ 0.       0.     ]\n",
      " [ 0.      -0.152  ]\n",
      " [ 0.09995 -0.152  ]\n",
      " [ 0.05    -0.08   ]]\n",
      "episode number =  5\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.72077488899231\n",
      "[[ 0.       0.     ]\n",
      " [ 0.       0.     ]\n",
      " [ 0.       0.     ]\n",
      " [ 0.      -0.152  ]\n",
      " [ 0.09995 -0.152  ]\n",
      " [ 0.05    -0.152  ]]\n",
      "episode number =  6\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.892320871353149\n",
      "[[ 0.       0.     ]\n",
      " [ 0.       0.     ]\n",
      " [ 0.       0.     ]\n",
      " [ 0.      -0.152  ]\n",
      " [ 0.09995 -0.152  ]\n",
      " [ 0.05    -0.2168 ]]\n",
      "episode number =  7\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.762541055679321\n",
      "[[ 0.        0.      ]\n",
      " [ 0.        0.      ]\n",
      " [ 0.        0.      ]\n",
      " [ 0.       -0.152   ]\n",
      " [ 0.299251 -0.2168  ]\n",
      " [ 0.05     -0.2168  ]]\n",
      "episode number =  8\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.8102333545684814\n",
      "[[ 0.        0.      ]\n",
      " [ 0.        0.      ]\n",
      " [ 0.        0.      ]\n",
      " [ 0.       -0.152   ]\n",
      " [ 0.299251 -0.2168  ]\n",
      " [ 0.       -0.08    ]\n",
      " [ 0.05     -0.2168  ]]\n",
      "episode number =  9\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.783119440078735\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.         -0.152     ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.         -0.08      ]\n",
      " [ 0.05       -0.2168    ]]\n",
      "episode number =  10\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.763619661331177\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.         -0.152     ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.         -0.152     ]\n",
      " [ 0.05       -0.2168    ]]\n",
      "episode number =  11\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  6.8894569873809814\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.         -0.152     ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.         -0.152     ]\n",
      " [ 0.05       -0.2168    ]]\n",
      "episode number =  12\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.722314119338989\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.         -0.152     ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.         -0.2168    ]\n",
      " [ 0.05       -0.2168    ]]\n",
      "episode number =  13\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.725255250930786\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.14985005 -0.2168    ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.         -0.2168    ]\n",
      " [ 0.05       -0.2168    ]]\n",
      "episode number =  14\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.889346361160278\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.14985005 -0.2168    ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.         -0.2168    ]\n",
      " [ 0.05       -0.27512   ]]\n",
      "episode number =  15\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.802965402603149\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.14985005 -0.2168    ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.         -0.2168    ]\n",
      " [ 0.09995    -0.327608  ]]\n",
      "episode number =  16\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.807178735733032\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.14985005 -0.2168    ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.         -0.2168    ]\n",
      " [ 0.09995    -0.3748472 ]]\n",
      "episode number =  17\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.770953416824341\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.1997002  -0.27512   ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.         -0.2168    ]\n",
      " [ 0.09995    -0.3748472 ]]\n",
      "episode number =  18\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.62804913520813\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.1997002  -0.327608  ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.         -0.2168    ]\n",
      " [ 0.09995    -0.3748472 ]]\n",
      "episode number =  19\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.644596338272095\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.1997002  -0.327608  ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.05       -0.27512   ]\n",
      " [ 0.09995    -0.3748472 ]]\n",
      "episode number =  20\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.708167314529419\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.1997002  -0.327608  ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.05       -0.327608  ]\n",
      " [ 0.09995    -0.3748472 ]]\n",
      "episode number =  21\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.860989809036255\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.1997002  -0.327608  ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.05       -0.327608  ]\n",
      " [ 0.299251   -0.41736248]]\n",
      "episode number =  22\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.677397012710571\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.299251   -0.3748472 ]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.05       -0.327608  ]\n",
      " [ 0.299251   -0.41736248]]\n",
      "episode number =  23\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.691962480545044\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.299251   -0.41736248]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.05       -0.327608  ]\n",
      " [ 0.299251   -0.41736248]]\n",
      "episode number =  24\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.748149156570435\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.299251   -0.45562623]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.05       -0.327608  ]\n",
      " [ 0.299251   -0.41736248]]\n",
      "episode number =  25\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.838664293289185\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.05       -0.327608  ]\n",
      " [ 0.299251   -0.41736248]]\n",
      "episode number =  26\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.837238550186157\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.05       -0.3748472 ]\n",
      " [ 0.299251   -0.41736248]]\n",
      "episode number =  27\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.806950807571411\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.05       -0.3748472 ]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  28\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.695873498916626\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.14985005 -0.41736248]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  29\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  7.070722818374634\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.49775599 -0.59105725]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.14985005 -0.41736248]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  30\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.84897255897522\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.49775599 -0.59105725]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.14985005 -0.45562623]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  31\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.776676416397095\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.49775599 -0.59105725]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.2495005  -0.49006361]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  32\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.801813364028931\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.54725823 -0.61195152]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.2495005  -0.49006361]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  33\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.8160765171051025\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.64611426 -0.63075637]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.2495005  -0.49006361]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  34\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.844460725784302\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.64611426 -0.63075637]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.3986028  -0.52105725]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  35\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.868437051773071\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.74477268 -0.64768073]\n",
      " [ 0.34895175 -0.27512   ]\n",
      " [ 0.3986028  -0.52105725]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  36\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.821129083633423\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.74477268 -0.64768073]\n",
      " [ 0.49775599 -0.327608  ]\n",
      " [ 0.3986028  -0.52105725]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  37\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.873591661453247\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.74477268 -0.66291266]\n",
      " [ 0.49775599 -0.327608  ]\n",
      " [ 0.3986028  -0.52105725]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  38\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.82669472694397\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.14985005 -0.08      ]\n",
      " [ 0.74477268 -0.66291266]\n",
      " [ 0.49775599 -0.327608  ]\n",
      " [ 0.44820419 -0.54895152]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  39\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  6.7362587451934814\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.152     ]\n",
      " [ 0.74477268 -0.66291266]\n",
      " [ 0.49775599 -0.327608  ]\n",
      " [ 0.44820419 -0.54895152]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  40\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.766148805618286\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.152     ]\n",
      " [ 0.74477268 -0.66291266]\n",
      " [ 0.49775599 -0.327608  ]\n",
      " [ 0.54725823 -0.57405637]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  41\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.737581491470337\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.152     ]\n",
      " [ 0.84323388 -0.67662139]\n",
      " [ 0.49775599 -0.327608  ]\n",
      " [ 0.54725823 -0.57405637]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  42\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.661401033401489\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.152     ]\n",
      " [ 0.89239065 -0.68895925]\n",
      " [ 0.49775599 -0.327608  ]\n",
      " [ 0.54725823 -0.57405637]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  43\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.779315233230591\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.152     ]\n",
      " [ 1.13743811 -0.70006333]\n",
      " [ 0.49775599 -0.327608  ]\n",
      " [ 0.54725823 -0.57405637]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  44\n",
      "action_current_episode = [0, 0, 0, 0, 0, 1]\n",
      "count_step =  6\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.827286958694458\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.152     ]\n",
      " [ 1.13743811 -0.70006333]\n",
      " [ 0.49775599 -0.327608  ]\n",
      " [ 0.64611426 -0.59665073]\n",
      " [ 0.3986028  -0.45562623]]\n",
      "episode number =  45\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.2\n",
      "9.2\n",
      "9.2\n",
      "9.2\n",
      "9.2\n",
      "9.2\n",
      "9.2\n",
      "DISTANCE FOR REWARD :  6.572387933731079\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.152     ]\n",
      " [ 1.13743811 -0.70006333]\n",
      " [ 0.49775599 -0.327608  ]\n",
      " [ 0.64611426 -0.59665073]\n",
      " [ 0.3986028  -0.45562623]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  46\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  7\n",
      "LOOP START :0.0\n",
      "8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTANCE FOR REWARD :  6.888776063919067\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.152     ]\n",
      " [ 1.13743811 -0.70006333]\n",
      " [ 0.49775599 -0.3748472 ]\n",
      " [ 0.64611426 -0.59665073]\n",
      " [ 0.3986028  -0.45562623]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  47\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.679706811904907\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.152     ]\n",
      " [ 1.13743811 -0.70006333]\n",
      " [ 0.49775599 -0.3748472 ]\n",
      " [ 0.64611426 -0.59665073]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  48\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.681242227554321\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.152     ]\n",
      " [ 1.13743811 -0.70006333]\n",
      " [ 0.49775599 -0.3748472 ]\n",
      " [ 0.79402791 -0.61698566]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  49\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.762464761734009\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.152     ]\n",
      " [ 1.13743811 -0.70006333]\n",
      " [ 0.49775599 -0.3748472 ]\n",
      " [ 0.79402791 -0.63528709]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  50\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  6.742471933364868\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.13743811 -0.70006333]\n",
      " [ 0.49775599 -0.3748472 ]\n",
      " [ 0.79402791 -0.63528709]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  51\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.792804956436157\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.13743811 -0.710057  ]\n",
      " [ 0.49775599 -0.3748472 ]\n",
      " [ 0.79402791 -0.63528709]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  52\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.791865587234497\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.13743811 -0.710057  ]\n",
      " [ 0.49775599 -0.3748472 ]\n",
      " [ 0.79402791 -0.65175838]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  53\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.5590879917144775\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.13743811 -0.710057  ]\n",
      " [ 0.89239065 -0.41736248]\n",
      " [ 0.79402791 -0.65175838]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  54\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  9\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.770488977432251\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.28387926 -0.7190513 ]\n",
      " [ 0.89239065 -0.41736248]\n",
      " [ 0.79402791 -0.65175838]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  55\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.696436166763306\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.28387926 -0.7190513 ]\n",
      " [ 0.89239065 -0.41736248]\n",
      " [ 0.89239065 -0.66658255]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  56\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.8577635288238525\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.28387926 -0.7190513 ]\n",
      " [ 0.99055676 -0.45562623]\n",
      " [ 0.89239065 -0.66658255]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  57\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.782954454421997\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.28387926 -0.7190513 ]\n",
      " [ 0.99055676 -0.49006361]\n",
      " [ 0.89239065 -0.66658255]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  58\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.844499826431274\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.57544621 -0.72714617]\n",
      " [ 0.99055676 -0.49006361]\n",
      " [ 0.89239065 -0.66658255]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  59\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  7\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.773854494094849\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.57544621 -0.72714617]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.89239065 -0.66658255]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  60\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.777071237564087\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.57544621 -0.72714617]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.89239065 -0.67992429]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  61\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.760953187942505\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.57544621 -0.73443155]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.89239065 -0.67992429]\n",
      " [ 0.3986028  -0.49006361]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  62\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.615884065628052\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.57544621 -0.73443155]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.89239065 -0.67992429]\n",
      " [ 0.74477268 -0.52105725]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  63\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  8\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.894331216812134\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.57544621 -0.73443155]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.69193186]\n",
      " [ 0.74477268 -0.52105725]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  64\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.695306062698364\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.57544621 -0.73443155]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.70273868]\n",
      " [ 0.74477268 -0.52105725]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  65\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.69599461555481\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.57544621 -0.73443155]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.71246481]\n",
      " [ 0.74477268 -0.52105725]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  66\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.731778383255005\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.57544621 -0.73443155]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.71246481]\n",
      " [ 1.0395662  -0.54895152]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  67\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  7\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.826342821121216\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.57544621 -0.73443155]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.71246481]\n",
      " [ 1.0395662  -0.57405637]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  68\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.703425645828247\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.57544621 -0.73443155]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.71246481]\n",
      " [ 1.0395662  -0.59665073]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  69\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.824842691421509\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 1.91340287 -0.7409884 ]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.71246481]\n",
      " [ 1.0395662  -0.59665073]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  70\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  8\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.659193277359009\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 2.00952797 -0.74688956]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.71246481]\n",
      " [ 1.0395662  -0.59665073]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  71\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.762416124343872\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 2.00952797 -0.74688956]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.72121833]\n",
      " [ 1.0395662  -0.59665073]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  72\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.937813997268677\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.2168    ]\n",
      " [ 2.05751845 -0.7522006 ]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.72121833]\n",
      " [ 1.0395662  -0.59665073]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  73\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  6.89283299446106\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.1997002  -0.27512   ]\n",
      " [ 2.05751845 -0.7522006 ]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.72121833]\n",
      " [ 1.0395662  -0.59665073]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  74\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  7.062402009963989\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.05751845 -0.7522006 ]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.72121833]\n",
      " [ 1.0395662  -0.59665073]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  75\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.713338136672974\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.05751845 -0.7522006 ]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.72121833]\n",
      " [ 1.08852664 -0.61698566]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  76\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.762154817581177\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.05751845 -0.7522006 ]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.72121833]\n",
      " [ 1.23511437 -0.63528709]\n",
      " [ 0.299251   -0.08      ]]\n",
      "episode number =  77\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.3\n",
      "DISTANCE FOR REWARD :  6.917210817337036\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.05751845 -0.7522006 ]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 0.99055676 -0.72121833]\n",
      " [ 1.23511437 -0.63528709]\n",
      " [ 0.299251   -0.08      ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  78\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.869364023208618\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.05751845 -0.7522006 ]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 1.0395662  -0.7290965 ]\n",
      " [ 1.23511437 -0.63528709]\n",
      " [ 0.299251   -0.08      ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  79\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.768655061721802\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.05751845 -0.7522006 ]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 1.0395662  -0.73618685]\n",
      " [ 1.23511437 -0.63528709]\n",
      " [ 0.299251   -0.08      ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  80\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.7744200229644775\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.05751845 -0.7522006 ]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 1.33259538 -0.74256816]\n",
      " [ 1.23511437 -0.63528709]\n",
      " [ 0.299251   -0.08      ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  81\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  7\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.761611223220825\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.05751845 -0.7522006 ]\n",
      " [ 1.0395662  -0.52105725]\n",
      " [ 1.33259538 -0.74256816]\n",
      " [ 1.28387926 -0.65175838]\n",
      " [ 0.299251   -0.08      ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  82\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.814310312271118\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.05751845 -0.7522006 ]\n",
      " [ 1.13743811 -0.54895152]\n",
      " [ 1.33259538 -0.74256816]\n",
      " [ 1.28387926 -0.65175838]\n",
      " [ 0.299251   -0.08      ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  83\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.6926023960113525\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.05751845 -0.7522006 ]\n",
      " [ 1.13743811 -0.54895152]\n",
      " [ 1.33259538 -0.74256816]\n",
      " [ 1.28387926 -0.66658255]\n",
      " [ 0.299251   -0.08      ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  84\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.920892000198364\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.05751845 -0.7522006 ]\n",
      " [ 1.13743811 -0.54895152]\n",
      " [ 1.33259538 -0.74256816]\n",
      " [ 1.33259538 -0.67992429]\n",
      " [ 0.299251   -0.08      ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  85\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.650843858718872\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.62967454 -0.75698054]\n",
      " [ 1.13743811 -0.54895152]\n",
      " [ 1.33259538 -0.74256816]\n",
      " [ 1.33259538 -0.67992429]\n",
      " [ 0.299251   -0.08      ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  86\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  13\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.837222337722778\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.67704487 -0.76128249]\n",
      " [ 1.13743811 -0.54895152]\n",
      " [ 1.33259538 -0.74256816]\n",
      " [ 1.33259538 -0.67992429]\n",
      " [ 0.299251   -0.08      ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  87\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.6808998584747314\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.67704487 -0.76128249]\n",
      " [ 1.13743811 -0.54895152]\n",
      " [ 1.33259538 -0.74831134]\n",
      " [ 1.33259538 -0.67992429]\n",
      " [ 0.299251   -0.08      ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  88\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.2\n",
      "9.2\n",
      "9.2\n",
      "9.2\n",
      "DISTANCE FOR REWARD :  6.150652170181274\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.67704487 -0.76128249]\n",
      " [ 1.13743811 -0.54895152]\n",
      " [ 1.33259538 -0.74831134]\n",
      " [ 1.33259538 -0.67992429]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  89\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.832539796829224\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.67704487 -0.76128249]\n",
      " [ 1.13743811 -0.54895152]\n",
      " [ 1.33259538 -0.74831134]\n",
      " [ 1.6722469  -0.69193186]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  90\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  8\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.6238672733306885\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 1.13743811 -0.54895152]\n",
      " [ 1.33259538 -0.74831134]\n",
      " [ 1.6722469  -0.69193186]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  91\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.991350412368774\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 1.13743811 -0.54895152]\n",
      " [ 1.33259538 -0.75348021]\n",
      " [ 1.6722469  -0.69193186]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  92\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.678331613540649\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 1.28387926 -0.57405637]\n",
      " [ 1.33259538 -0.75348021]\n",
      " [ 1.6722469  -0.69193186]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  93\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.714074373245239\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 1.28387926 -0.57405637]\n",
      " [ 1.62387077 -0.75813219]\n",
      " [ 1.6722469  -0.69193186]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  94\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  7\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.877612352371216\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 1.28387926 -0.57405637]\n",
      " [ 2.05751845 -0.76231897]\n",
      " [ 1.6722469  -0.69193186]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  95\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  10\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.8890907764434814\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 1.6722469  -0.59665073]\n",
      " [ 2.05751845 -0.76231897]\n",
      " [ 1.6722469  -0.69193186]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  96\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  9\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.739295244216919\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 2.05751845 -0.61698566]\n",
      " [ 2.05751845 -0.76231897]\n",
      " [ 1.6722469  -0.69193186]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  97\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  9\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.748605966567993\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 2.05751845 -0.61698566]\n",
      " [ 2.15335547 -0.76608707]\n",
      " [ 1.6722469  -0.69193186]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  98\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.981626749038696\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 2.05751845 -0.63528709]\n",
      " [ 2.15335547 -0.76608707]\n",
      " [ 1.6722469  -0.69193186]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  99\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.802671670913696\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 2.05751845 -0.63528709]\n",
      " [ 2.15335547 -0.76947837]\n",
      " [ 1.6722469  -0.69193186]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  100\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.756004571914673\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.3986028  -0.397608  ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 2.05751845 -0.63528709]\n",
      " [ 2.15335547 -0.76947837]\n",
      " [ 1.72057465 -0.70273868]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  101\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  6.802884340286255\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.54725823 -0.4378472 ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 2.05751845 -0.63528709]\n",
      " [ 2.15335547 -0.76947837]\n",
      " [ 1.72057465 -0.70273868]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  102\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.7122719287872314\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.54725823 -0.4378472 ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 2.05751845 -0.63528709]\n",
      " [ 2.15335547 -0.76947837]\n",
      " [ 1.91340287 -0.71246481]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  103\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.704566240310669\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.54725823 -0.4378472 ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 2.05751845 -0.65175838]\n",
      " [ 2.15335547 -0.76947837]\n",
      " [ 1.91340287 -0.71246481]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  104\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.735382318496704\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.54725823 -0.4378472 ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 2.05751845 -0.65175838]\n",
      " [ 2.29675191 -0.77253053]\n",
      " [ 1.91340287 -0.71246481]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  105\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.825613260269165\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.54725823 -0.4378472 ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 2.05751845 -0.65175838]\n",
      " [ 2.29675191 -0.77253053]\n",
      " [ 2.00952797 -0.72121833]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  106\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.806567430496216\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.54725823 -0.4378472 ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 2.05751845 -0.65175838]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 2.00952797 -0.72121833]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  107\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.7623560428619385\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.54725823 -0.4378472 ]\n",
      " [ 2.77164346 -0.76515424]\n",
      " [ 2.20120211 -0.66658255]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 2.00952797 -0.72121833]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  108\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.702869653701782\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.54725823 -0.4378472 ]\n",
      " [ 2.91318689 -0.76863881]\n",
      " [ 2.20120211 -0.66658255]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 2.00952797 -0.72121833]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  109\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.79140305519104\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.54725823 -0.4378472 ]\n",
      " [ 2.91318689 -0.76863881]\n",
      " [ 2.20120211 -0.66658255]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 2.34445516 -0.7290965 ]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  110\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  8\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.90899395942688\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.54725823 -0.4378472 ]\n",
      " [ 2.91318689 -0.76863881]\n",
      " [ 2.20120211 -0.66658255]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 2.43971859 -0.73618685]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  111\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  6.740769624710083\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 2.91318689 -0.76863881]\n",
      " [ 2.20120211 -0.66658255]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 2.43971859 -0.73618685]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  112\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.00099945068359375\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.730333566665649\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 2.91318689 -0.76863881]\n",
      " [ 2.24900091 -0.67992429]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 2.43971859 -0.73618685]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  113\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.920887231826782\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 2.91318689 -0.76863881]\n",
      " [ 2.24900091 -0.69193186]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 2.43971859 -0.73618685]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  114\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.773735284805298\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 2.91318689 -0.76863881]\n",
      " [ 2.24900091 -0.70273868]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 2.43971859 -0.73618685]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  115\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.882758378982544\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 2.91318689 -0.77177493]\n",
      " [ 2.24900091 -0.70273868]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 2.43971859 -0.73618685]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  116\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.876788377761841\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 2.91318689 -0.77177493]\n",
      " [ 2.24900091 -0.70273868]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 2.77164346 -0.74256816]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  117\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  8\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.745319604873657\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 2.91318689 -0.77177493]\n",
      " [ 2.24900091 -0.70273868]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 3.79982994 -0.74831134]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  118\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  23\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.803791284561157\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 3.70729081 -0.77459744]\n",
      " [ 2.24900091 -0.70273868]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 3.79982994 -0.74831134]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  119\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  18\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.877296686172485\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 3.70729081 -0.77459744]\n",
      " [ 2.24900091 -0.70273868]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 4.21397214 -0.75348021]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  120\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  10\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.639554262161255\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 3.70729081 -0.77459744]\n",
      " [ 2.24900091 -0.70273868]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 4.66977753 -0.75813219]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  121\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  11\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.790719270706177\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 3.70729081 -0.77459744]\n",
      " [ 2.24900091 -0.70273868]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 4.80563225 -0.76231897]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  122\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0009970664978027344\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.854800462722778\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.35119291 -0.7771377 ]\n",
      " [ 2.24900091 -0.70273868]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 4.80563225 -0.76231897]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  123\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  15\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.075812578201294\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.35119291 -0.7771377 ]\n",
      " [ 2.24900091 -0.70273868]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 4.80563225 -0.76608707]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  124\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.746978044509888\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.35119291 -0.7771377 ]\n",
      " [ 2.24900091 -0.70273868]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 5.47882286 -0.76947837]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  125\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  16\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.763028383255005\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.44244487 -0.77942393]\n",
      " [ 2.24900091 -0.70273868]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 5.47882286 -0.76947837]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  126\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.657845735549927\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.44244487 -0.77942393]\n",
      " [ 2.24900091 -0.70273868]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 5.83374818 -0.77253053]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  127\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  9\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.7150537967681885\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.44244487 -0.77942393]\n",
      " [ 2.91318689 -0.71246481]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 5.83374818 -0.77253053]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  128\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  15\n",
      "LOOP START :0.0009968280792236328\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.888050317764282\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.44244487 -0.77942393]\n",
      " [ 2.91318689 -0.71246481]\n",
      " [ 2.43971859 -0.77527748]\n",
      " [ 5.92203651 -0.77527748]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  129\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.6274940967559814\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.44244487 -0.77942393]\n",
      " [ 2.91318689 -0.71246481]\n",
      " [ 3.00731343 -0.77774973]\n",
      " [ 5.92203651 -0.77527748]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  130\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.82911229133606\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.44244487 -0.77942393]\n",
      " [ 2.91318689 -0.72121833]\n",
      " [ 3.00731343 -0.77774973]\n",
      " [ 5.92203651 -0.77527748]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  131\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.7936012744903564\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.66977753 -0.78148153]\n",
      " [ 2.91318689 -0.72121833]\n",
      " [ 3.00731343 -0.77774973]\n",
      " [ 5.92203651 -0.77527748]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  132\n",
      "action_current_episode = [0, 0, 0, 0, 0, 1]\n",
      "count_step =  6\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.707291841506958\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.66977753 -0.78148153]\n",
      " [ 4.30549841 -0.7290965 ]\n",
      " [ 3.00731343 -0.77774973]\n",
      " [ 5.92203651 -0.77527748]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  133\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  31\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.122212648391724\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.89597579 -0.78333338]\n",
      " [ 4.30549841 -0.7290965 ]\n",
      " [ 3.00731343 -0.77774973]\n",
      " [ 5.92203651 -0.77527748]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  134\n",
      "action_current_episode = [0, 0, 0, 0, 0, 1]\n",
      "count_step =  6\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.856123208999634\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.89597579 -0.78333338]\n",
      " [ 4.30549841 -0.73618685]\n",
      " [ 3.00731343 -0.77774973]\n",
      " [ 5.92203651 -0.77527748]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  135\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.976564645767212\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.89597579 -0.78333338]\n",
      " [ 4.71510775 -0.74256816]\n",
      " [ 3.00731343 -0.77774973]\n",
      " [ 5.92203651 -0.77527748]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  136\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  10\n",
      "LOOP START :0.0009963512420654297\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.758196115493774\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.89597579 -0.78333338]\n",
      " [ 4.71510775 -0.74256816]\n",
      " [ 3.00731343 -0.77774973]\n",
      " [ 5.92203651 -0.77774973]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  137\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.887863397598267\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 4.89597579 -0.78333338]\n",
      " [ 4.71510775 -0.74256816]\n",
      " [ 3.75358352 -0.77997476]\n",
      " [ 5.92203651 -0.77774973]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  138\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  17\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.585754632949829\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 5.0311526  -0.78500004]\n",
      " [ 4.71510775 -0.74256816]\n",
      " [ 3.75358352 -0.77997476]\n",
      " [ 5.92203651 -0.77774973]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  139\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.74519944190979\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 5.0311526  -0.78500004]\n",
      " [ 4.71510775 -0.74256816]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 5.92203651 -0.77774973]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  140\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  26\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.700799226760864\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 5.0311526  -0.78500004]\n",
      " [ 4.89597579 -0.74831134]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 5.92203651 -0.77774973]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  141\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.752911806106567\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 5.12104532 -0.78650004]\n",
      " [ 4.89597579 -0.74831134]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 5.92203651 -0.77774973]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  142\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.8613951206207275\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 5.12104532 -0.78650004]\n",
      " [ 5.38964677 -0.75348021]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 5.92203651 -0.77774973]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  143\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  12\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.738612413406372\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 5.12104532 -0.78650004]\n",
      " [ 5.38964677 -0.75348021]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 6.09808408 -0.77997476]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  144\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0009996891021728516\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.762331247329712\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 5.12104532 -0.78650004]\n",
      " [ 5.43425712 -0.75813219]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 6.09808408 -0.77997476]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  145\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.824195146560669\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 5.12104532 -0.78650004]\n",
      " [ 6.22965816 -0.76231897]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 6.09808408 -0.77997476]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  146\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  19\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.833070993423462\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 5.12104532 -0.78650004]\n",
      " [ 6.22965816 -0.76231897]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 6.09808408 -0.78197728]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  147\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.919774293899536\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 5.12104532 -0.78785003]\n",
      " [ 6.22965816 -0.76231897]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 6.09808408 -0.78197728]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  148\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.674391984939575\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 5.12104532 -0.78785003]\n",
      " [ 7.56638093 -0.76608707]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 6.09808408 -0.78197728]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  149\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  32\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.686791658401489\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 5.12104532 -0.78785003]\n",
      " [ 7.56638093 -0.76608707]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 6.49162453 -0.78377955]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  150\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  10\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.782815217971802\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 6.14198599 -0.78906503]\n",
      " [ 7.56638093 -0.76608707]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 6.49162453 -0.78377955]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  151\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  24\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.809258699417114\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 6.14198599 -0.78906503]\n",
      " [ 7.56638093 -0.76947837]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 6.49162453 -0.78377955]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  152\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.642892122268677\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 6.14198599 -0.78906503]\n",
      " [ 7.56638093 -0.76947837]\n",
      " [ 4.89597579 -0.78197728]\n",
      " [ 6.62201918 -0.7854016 ]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  153\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.730812311172485\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 6.14198599 -0.78906503]\n",
      " [ 7.56638093 -0.76947837]\n",
      " [ 5.47882286 -0.78377955]\n",
      " [ 6.62201918 -0.7854016 ]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  154\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  14\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.7200844287872314\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 6.14198599 -0.78906503]\n",
      " [ 7.56638093 -0.76947837]\n",
      " [ 5.47882286 -0.78377955]\n",
      " [ 7.77812511 -0.78686144]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  155\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  28\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.8522560596466064\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 6.14198599 -0.78906503]\n",
      " [ 7.56638093 -0.76947837]\n",
      " [ 5.47882286 -0.78377955]\n",
      " [ 7.90466411 -0.78817529]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  156\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.731460809707642\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 6.14198599 -0.78906503]\n",
      " [ 7.56638093 -0.76947837]\n",
      " [ 5.47882286 -0.7854016 ]\n",
      " [ 7.90466411 -0.78817529]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  157\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.149956941604614\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 6.14198599 -0.78906503]\n",
      " [ 7.56638093 -0.76947837]\n",
      " [ 5.47882286 -0.7854016 ]\n",
      " [ 8.11472026 -0.78935776]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  158\n",
      "action_current_episode = [0, 0, 0, 0, 0, 1]\n",
      "count_step =  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.781819581985474\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.59671098 -0.47406248]\n",
      " [ 7.01086303 -0.79015853]\n",
      " [ 7.56638093 -0.76947837]\n",
      " [ 5.47882286 -0.7854016 ]\n",
      " [ 8.11472026 -0.78935776]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  159\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  21\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  6.85175347328186\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.64611426 -0.50665623]\n",
      " [ 7.01086303 -0.79015853]\n",
      " [ 7.56638093 -0.76947837]\n",
      " [ 5.47882286 -0.7854016 ]\n",
      " [ 8.11472026 -0.78935776]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  160\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.000645875930786\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.64611426 -0.50665623]\n",
      " [ 7.01086303 -0.79015853]\n",
      " [ 7.56638093 -0.76947837]\n",
      " [ 5.47882286 -0.72186144]\n",
      " [ 8.11472026 -0.78935776]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  161\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.000997781753540039\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.875781297683716\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.64611426 -0.50665623]\n",
      " [ 7.01086303 -0.79015853]\n",
      " [ 7.56638093 -0.76947837]\n",
      " [ 6.18584401 -0.72967529]\n",
      " [ 8.11472026 -0.78935776]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  162\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  17\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.731226205825806\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.64611426 -0.50665623]\n",
      " [ 7.01086303 -0.79015853]\n",
      " [ 7.98881269 -0.77253053]\n",
      " [ 6.18584401 -0.72967529]\n",
      " [ 8.11472026 -0.78935776]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  163\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  11\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.09498143196106\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.64611426 -0.50665623]\n",
      " [ 7.01086303 -0.79015853]\n",
      " [ 7.98881269 -0.77253053]\n",
      " [ 7.39622126 -0.73670776]\n",
      " [ 8.11472026 -0.78935776]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  164\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  29\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.754318475723267\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.64611426 -0.50665623]\n",
      " [ 7.01086303 -0.79015853]\n",
      " [ 7.98881269 -0.77253053]\n",
      " [ 7.39622126 -0.73670776]\n",
      " [ 8.19844893 -0.79042199]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  165\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.85254693031311\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.64611426 -0.50665623]\n",
      " [ 7.01086303 -0.79015853]\n",
      " [ 7.98881269 -0.77253053]\n",
      " [ 7.56638093 -0.74303699]\n",
      " [ 8.19844893 -0.79042199]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  166\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.70629620552063\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.64611426 -0.50665623]\n",
      " [ 7.01086303 -0.79015853]\n",
      " [ 7.98881269 -0.77253053]\n",
      " [ 7.56638093 -0.74303699]\n",
      " [ 8.90341862 -0.79137979]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  167\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  18\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.829559564590454\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.64611426 -0.50665623]\n",
      " [ 7.60881455 -0.79114267]\n",
      " [ 7.98881269 -0.77253053]\n",
      " [ 7.56638093 -0.74303699]\n",
      " [ 8.90341862 -0.79137979]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  168\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  15\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.786298036575317\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.64611426 -0.50665623]\n",
      " [ 7.60881455 -0.79114267]\n",
      " [ 8.15660554 -0.77527748]\n",
      " [ 7.56638093 -0.74303699]\n",
      " [ 8.90341862 -0.79137979]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  169\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.739848375320435\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.64611426 -0.50665623]\n",
      " [ 7.60881455 -0.79114267]\n",
      " [ 8.8622809  -0.77774973]\n",
      " [ 7.56638093 -0.74303699]\n",
      " [ 8.90341862 -0.79137979]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  170\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  18\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  6.966999292373657\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 7.60881455 -0.79114267]\n",
      " [ 8.8622809  -0.77774973]\n",
      " [ 7.56638093 -0.74303699]\n",
      " [ 8.90341862 -0.79137979]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  171\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.8840858936309814\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 7.60881455 -0.79114267]\n",
      " [ 8.8622809  -0.77774973]\n",
      " [ 7.56638093 -0.74303699]\n",
      " [ 9.06755853 -0.79224181]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  172\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.616597414016724\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 7.60881455 -0.79114267]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.56638093 -0.74303699]\n",
      " [ 9.06755853 -0.79224181]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  173\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.782397508621216\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 7.60881455 -0.79114267]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [ 9.06755853 -0.79224181]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  174\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  7\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.83975625038147\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 7.60881455 -0.79114267]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [ 9.75787096 -0.79301763]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  175\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  18\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.737451791763306\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 7.60881455 -0.79114267]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [ 9.79811309 -0.79371587]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  176\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.828972101211548\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 7.60881455 -0.79114267]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [ 9.79811309 -0.79434428]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  177\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.818547487258911\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 7.90466411 -0.79202841]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [ 9.79811309 -0.79434428]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  178\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  8\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.822203874588013\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 8.07279305 -0.79282557]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [ 9.79811309 -0.79434428]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  179\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.8091957569122314\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 8.07279305 -0.79282557]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [10.03872218 -0.79490985]\n",
      " [ 0.44820419 -0.152     ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  180\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  7\n",
      "LOOP START :0.0\n",
      "9.2\n",
      "9.2\n",
      "9.2\n",
      "DISTANCE FOR REWARD :  6.196393251419067\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 8.07279305 -0.79282557]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [10.03872218 -0.79490985]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  181\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.804307222366333\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 8.98557068 -0.79354301]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [10.03872218 -0.79490985]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  182\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  23\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.733302354812622\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 9.06755853 -0.79418871]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [10.03872218 -0.79490985]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  183\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.689924478530884\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 9.06755853 -0.79418871]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [10.07868346 -0.79541887]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  184\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTANCE FOR REWARD :  6.784411668777466\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 9.06755853 -0.79418871]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [10.23812936 -0.79587698]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  185\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.810223817825317\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 9.06755853 -0.79418871]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [11.29785906 -0.79628928]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  186\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  28\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.939351320266724\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 9.10849097 -0.79476984]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.82034699 -0.74873329]\n",
      " [11.29785906 -0.79628928]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  187\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.694378137588501\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 9.10849097 -0.79476984]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.94675945 -0.75385996]\n",
      " [11.29785906 -0.79628928]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  188\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.797269105911255\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 9.10849097 -0.79476984]\n",
      " [ 8.90341862 -0.77997476]\n",
      " [ 7.98881269 -0.75847396]\n",
      " [11.29785906 -0.79628928]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  189\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.714665651321411\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 2.91318689 -0.53599061]\n",
      " [ 9.10849097 -0.79476984]\n",
      " [ 9.23104286 -0.78197728]\n",
      " [ 7.98881269 -0.75847396]\n",
      " [11.29785906 -0.79628928]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  190\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  9\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  6.8095104694366455\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.25975817 -0.56239155]\n",
      " [ 9.10849097 -0.79476984]\n",
      " [ 9.23104286 -0.78197728]\n",
      " [ 7.98881269 -0.75847396]\n",
      " [11.29785906 -0.79628928]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  191\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  30\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.825987100601196\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.25975817 -0.56239155]\n",
      " [ 9.95867958 -0.79529285]\n",
      " [ 9.23104286 -0.78197728]\n",
      " [ 7.98881269 -0.75847396]\n",
      " [11.29785906 -0.79628928]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  192\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  22\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.757616281509399\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.25975817 -0.56239155]\n",
      " [ 9.95867958 -0.79529285]\n",
      " [ 9.23104286 -0.78197728]\n",
      " [ 8.07279305 -0.76262657]\n",
      " [11.29785906 -0.79628928]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  193\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.755003213882446\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.25975817 -0.56239155]\n",
      " [10.15848617 -0.79576357]\n",
      " [ 9.23104286 -0.78197728]\n",
      " [ 8.07279305 -0.76262657]\n",
      " [11.29785906 -0.79628928]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  194\n",
      "action_current_episode = [0, 0, 0, 0, 0, 1]\n",
      "count_step =  6\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.818342447280884\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.25975817 -0.56239155]\n",
      " [10.15848617 -0.79576357]\n",
      " [ 9.71758854 -0.78377955]\n",
      " [ 8.07279305 -0.76262657]\n",
      " [11.29785906 -0.79628928]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  195\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  13\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.71039891242981\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.25975817 -0.56239155]\n",
      " [10.15848617 -0.79576357]\n",
      " [ 9.71758854 -0.78377955]\n",
      " [ 8.61458838 -0.76636391]\n",
      " [11.29785906 -0.79628928]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  196\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  14\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  6.822980165481567\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [ 9.71758854 -0.78377955]\n",
      " [ 8.61458838 -0.76636391]\n",
      " [11.29785906 -0.79628928]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  197\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.140136957168579\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [ 9.71758854 -0.78377955]\n",
      " [ 8.61458838 -0.76636391]\n",
      " [12.70436082 -0.79666035]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  198\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  38\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.799811601638794\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [ 9.71758854 -0.78377955]\n",
      " [ 8.61458838 -0.76636391]\n",
      " [13.25989629 -0.79699432]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  199\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  16\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.659172296524048\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [ 9.71758854 -0.78377955]\n",
      " [ 8.61458838 -0.76636391]\n",
      " [14.41753743 -0.79729489]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  200\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  33\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.869600534439087\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [10.39693843 -0.7854016 ]\n",
      " [ 8.61458838 -0.76636391]\n",
      " [14.41753743 -0.79729489]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  201\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  18\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.857426881790161\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [10.986844   -0.78686144]\n",
      " [ 8.61458838 -0.76636391]\n",
      " [14.41753743 -0.79729489]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  202\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  16\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.803926706314087\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [10.986844   -0.78686144]\n",
      " [ 8.61458838 -0.76636391]\n",
      " [14.59509427 -0.7975654 ]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  203\n",
      "action_current_episode = [0, 0, 0, 0, 0, 1]\n",
      "count_step =  6\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.071173906326294\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [10.986844   -0.78686144]\n",
      " [ 9.27181182 -0.76972752]\n",
      " [14.59509427 -0.7975654 ]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  204\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  17\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.784967660903931\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [10.986844   -0.78686144]\n",
      " [ 9.27181182 -0.76972752]\n",
      " [15.29650565 -0.79780886]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  205\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  21\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.84528374671936\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [11.06483129 -0.78817529]\n",
      " [ 9.27181182 -0.76972752]\n",
      " [15.29650565 -0.79780886]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  206\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.796581506729126\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [11.06483129 -0.78817529]\n",
      " [ 9.43448036 -0.77275477]\n",
      " [15.29650565 -0.79780886]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  207\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.470593690872192\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [11.06483129 -0.78817529]\n",
      " [ 9.43448036 -0.77547929]\n",
      " [15.29650565 -0.79780886]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  208\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.806734323501587\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [11.3365612  -0.78935776]\n",
      " [ 9.43448036 -0.77547929]\n",
      " [15.29650565 -0.79780886]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  209\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.812133073806763\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [11.3365612  -0.78935776]\n",
      " [ 9.51557084 -0.77793136]\n",
      " [15.29650565 -0.79780886]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  210\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.840157747268677\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [11.37522464 -0.79042199]\n",
      " [ 9.51557084 -0.77793136]\n",
      " [15.29650565 -0.79780886]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  211\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.827455759048462\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [11.37522464 -0.79042199]\n",
      " [ 9.51557084 -0.77793136]\n",
      " [15.33120914 -0.79802797]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  212\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.748193025588989\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [10.15848617 -0.79576357]\n",
      " [11.37522464 -0.79042199]\n",
      " [ 9.51557084 -0.77793136]\n",
      " [16.72456724 -0.79822518]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  213\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  42\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.792053461074829\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [11.7597389  -0.79618721]\n",
      " [11.37522464 -0.79042199]\n",
      " [ 9.51557084 -0.77793136]\n",
      " [16.72456724 -0.79822518]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  214\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  42\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.758211374282837\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [13.07564338 -0.79656849]\n",
      " [11.37522464 -0.79042199]\n",
      " [ 9.51557084 -0.77793136]\n",
      " [16.72456724 -0.79822518]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  215\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  36\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.759796380996704\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [13.18630571 -0.79691164]\n",
      " [11.37522464 -0.79042199]\n",
      " [ 9.51557084 -0.77793136]\n",
      " [16.72456724 -0.79822518]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  216\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.736722230911255\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [13.18630571 -0.79691164]\n",
      " [11.45243556 -0.79137979]\n",
      " [ 9.51557084 -0.77793136]\n",
      " [16.72456724 -0.79822518]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  217\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.894848108291626\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [13.22311941 -0.79722048]\n",
      " [11.45243556 -0.79137979]\n",
      " [ 9.51557084 -0.77793136]\n",
      " [16.72456724 -0.79822518]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  218\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.725482225418091\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [14.41753743 -0.79749843]\n",
      " [11.45243556 -0.79137979]\n",
      " [ 9.51557084 -0.77793136]\n",
      " [16.72456724 -0.79822518]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  219\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  34\n",
      "LOOP START :0.000997304916381836\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.797988176345825\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [14.41753743 -0.79749843]\n",
      " [11.45243556 -0.79137979]\n",
      " [ 9.51557084 -0.77793136]\n",
      " [16.92372137 -0.79840266]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  220\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  7\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.65394139289856\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [14.52417811 -0.79774859]\n",
      " [11.45243556 -0.79137979]\n",
      " [ 9.51557084 -0.77793136]\n",
      " [16.92372137 -0.79840266]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  221\n",
      "action_current_episode = [0, 0, 0, 1]\n",
      "count_step =  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.699761629104614\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [14.52417811 -0.79774859]\n",
      " [12.14042528 -0.79224181]\n",
      " [ 9.51557084 -0.77793136]\n",
      " [16.92372137 -0.79840266]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  222\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  19\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.765167474746704\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [14.52417811 -0.79774859]\n",
      " [12.14042528 -0.79224181]\n",
      " [10.79119165 -0.78013823]\n",
      " [16.92372137 -0.79840266]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  223\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  33\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.737490892410278\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [14.52417811 -0.79774859]\n",
      " [12.14042528 -0.79301763]\n",
      " [10.79119165 -0.78013823]\n",
      " [16.92372137 -0.79840266]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  224\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.831316232681274\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 4.57898091 -0.58615239]\n",
      " [14.52417811 -0.79774859]\n",
      " [12.55480456 -0.79371587]\n",
      " [10.79119165 -0.78013823]\n",
      " [16.92372137 -0.79840266]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  225\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  12\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  6.759872674942017\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.92203651 -0.60753715]\n",
      " [14.52417811 -0.79774859]\n",
      " [12.55480456 -0.79371587]\n",
      " [10.79119165 -0.78013823]\n",
      " [16.92372137 -0.79840266]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  226\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  31\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.853188753128052\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.92203651 -0.60753715]\n",
      " [14.52417811 -0.79774859]\n",
      " [12.55480456 -0.79371587]\n",
      " [11.37522464 -0.7821244 ]\n",
      " [16.92372137 -0.79840266]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  227\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  16\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.816770792007446\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.92203651 -0.60753715]\n",
      " [14.52417811 -0.79774859]\n",
      " [13.29663639 -0.79434428]\n",
      " [11.37522464 -0.7821244 ]\n",
      " [16.92372137 -0.79840266]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  228\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  21\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.7353270053863525\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.92203651 -0.60753715]\n",
      " [15.01762419 -0.79797373]\n",
      " [13.29663639 -0.79434428]\n",
      " [11.37522464 -0.7821244 ]\n",
      " [16.92372137 -0.79840266]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  229\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  15\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  6.935426950454712\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.92203651 -0.62678344]\n",
      " [15.01762419 -0.79797373]\n",
      " [13.29663639 -0.79434428]\n",
      " [11.37522464 -0.7821244 ]\n",
      " [16.92372137 -0.79840266]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  230\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.630019426345825\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.92203651 -0.62678344]\n",
      " [15.01762419 -0.79797373]\n",
      " [13.29663639 -0.79434428]\n",
      " [11.72146036 -0.78391196]\n",
      " [16.92372137 -0.79840266]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  231\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  10\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.7755444049835205\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.92203651 -0.62678344]\n",
      " [15.01762419 -0.79797373]\n",
      " [13.29663639 -0.79434428]\n",
      " [11.72146036 -0.78391196]\n",
      " [17.18740732 -0.79856239]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  232\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  9\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.995459794998169\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.92203651 -0.62678344]\n",
      " [15.01762419 -0.79797373]\n",
      " [15.60759068 -0.79490985]\n",
      " [11.72146036 -0.78391196]\n",
      " [17.18740732 -0.79856239]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  233\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.756723642349243\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.92203651 -0.62678344]\n",
      " [15.01762419 -0.79797373]\n",
      " [17.28574669 -0.79541887]\n",
      " [11.72146036 -0.78391196]\n",
      " [17.18740732 -0.79856239]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  234\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  51\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.699204683303833\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.92203651 -0.62678344]\n",
      " [15.29650565 -0.79817636]\n",
      " [17.28574669 -0.79541887]\n",
      " [11.72146036 -0.78391196]\n",
      " [17.18740732 -0.79856239]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  235\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  9\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.775758981704712\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.92203651 -0.62678344]\n",
      " [15.29650565 -0.79817636]\n",
      " [17.35114248 -0.79587698]\n",
      " [11.72146036 -0.78391196]\n",
      " [17.18740732 -0.79856239]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  236\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.68230938911438\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.92203651 -0.62678344]\n",
      " [15.60759068 -0.79835872]\n",
      " [17.35114248 -0.79587698]\n",
      " [11.72146036 -0.78391196]\n",
      " [17.18740732 -0.79856239]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  237\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  10\n",
      "LOOP START :0.0009965896606445312\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.803821802139282\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.92203651 -0.62678344]\n",
      " [15.60759068 -0.79835872]\n",
      " [17.74078111 -0.79628928]\n",
      " [11.72146036 -0.78391196]\n",
      " [17.18740732 -0.79856239]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  238\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  13\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  6.798952341079712\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [15.60759068 -0.79835872]\n",
      " [17.74078111 -0.79628928]\n",
      " [11.72146036 -0.78391196]\n",
      " [17.18740732 -0.79856239]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  239\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.684624910354614\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [15.60759068 -0.79835872]\n",
      " [17.74078111 -0.79628928]\n",
      " [11.72146036 -0.78391196]\n",
      " [17.579      -0.79870615]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  240\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  13\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.817143678665161\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [15.60759068 -0.79835872]\n",
      " [17.74078111 -0.79628928]\n",
      " [12.25389047 -0.78552077]\n",
      " [17.579      -0.79870615]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  241\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  15\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.840310335159302\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [15.60759068 -0.79835872]\n",
      " [17.74078111 -0.79628928]\n",
      " [12.55480456 -0.78696869]\n",
      " [17.579      -0.79870615]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  242\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  9\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.647412538528442\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [16.11988122 -0.79852285]\n",
      " [17.74078111 -0.79628928]\n",
      " [12.55480456 -0.78696869]\n",
      " [17.579      -0.79870615]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  243\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  16\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.727441072463989\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [17.25299969 -0.79867056]\n",
      " [17.74078111 -0.79628928]\n",
      " [12.55480456 -0.78696869]\n",
      " [17.579      -0.79870615]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  244\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  35\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISTANCE FOR REWARD :  6.661620378494263\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [17.25299969 -0.79867056]\n",
      " [19.86251226 -0.79666035]\n",
      " [12.55480456 -0.78696869]\n",
      " [17.579      -0.79870615]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  245\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  69\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  7.00739598274231\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [17.25299969 -0.79867056]\n",
      " [19.86251226 -0.79666035]\n",
      " [14.48866677 -0.78827182]\n",
      " [17.579      -0.79870615]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  246\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  54\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.822821855545044\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [17.25299969 -0.79867056]\n",
      " [19.86251226 -0.79666035]\n",
      " [14.48866677 -0.78827182]\n",
      " [17.579      -0.79883554]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  247\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.817133188247681\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [17.25299969 -0.79867056]\n",
      " [19.86251226 -0.79666035]\n",
      " [14.48866677 -0.78827182]\n",
      " [17.93385318 -0.79895198]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  248\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  12\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.7132275104522705\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [17.25299969 -0.79867056]\n",
      " [19.86251226 -0.79666035]\n",
      " [14.48866677 -0.78944464]\n",
      " [17.93385318 -0.79895198]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  249\n",
      "action_current_episode = [1]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.744947671890259\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [17.41640755 -0.79880351]\n",
      " [19.86251226 -0.79666035]\n",
      " [14.48866677 -0.78944464]\n",
      " [17.93385318 -0.79895198]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  250\n",
      "action_current_episode = [0, 0, 0, 0, 0, 1]\n",
      "count_step =  6\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.718909502029419\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [17.41640755 -0.79880351]\n",
      " [19.86251226 -0.79666035]\n",
      " [14.9826068  -0.79050017]\n",
      " [17.93385318 -0.79895198]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  251\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  15\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.877358675003052\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [17.41640755 -0.79880351]\n",
      " [19.86251226 -0.79666035]\n",
      " [15.50420676 -0.79145016]\n",
      " [17.93385318 -0.79895198]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  252\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  16\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.6708595752716064\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [17.67616577 -0.79892316]\n",
      " [19.86251226 -0.79666035]\n",
      " [15.50420676 -0.79145016]\n",
      " [17.93385318 -0.79895198]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  253\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  9\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.699153184890747\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [17.67616577 -0.79892316]\n",
      " [21.81651088 -0.79699432]\n",
      " [15.50420676 -0.79145016]\n",
      " [17.93385318 -0.79895198]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  254\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  68\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.76810097694397\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [17.67616577 -0.79892316]\n",
      " [21.81651088 -0.79699432]\n",
      " [15.88176889 -0.79230514]\n",
      " [17.93385318 -0.79895198]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  255\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.830651521682739\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [18.78847716 -0.79903084]\n",
      " [21.81651088 -0.79699432]\n",
      " [15.88176889 -0.79230514]\n",
      " [17.93385318 -0.79895198]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  256\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  36\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.75556492805481\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [19.06825987 -0.79912776]\n",
      " [21.81651088 -0.79699432]\n",
      " [15.88176889 -0.79230514]\n",
      " [17.93385318 -0.79895198]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  257\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  10\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.783974885940552\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [19.46796864 -0.79921498]\n",
      " [21.81651088 -0.79699432]\n",
      " [15.88176889 -0.79230514]\n",
      " [17.93385318 -0.79895198]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  258\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  14\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.660707712173462\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [19.65070346 -0.79929348]\n",
      " [21.81651088 -0.79699432]\n",
      " [15.88176889 -0.79230514]\n",
      " [17.93385318 -0.79895198]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  259\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  7\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.774856805801392\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [19.65070346 -0.79929348]\n",
      " [21.81651088 -0.79699432]\n",
      " [15.88176889 -0.79230514]\n",
      " [17.99795341 -0.79905679]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  260\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  7.00082802772522\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [19.65070346 -0.79929348]\n",
      " [21.81651088 -0.79699432]\n",
      " [17.35114248 -0.79307463]\n",
      " [17.99795341 -0.79905679]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  261\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  45\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.8731138706207275\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [19.65070346 -0.79929348]\n",
      " [21.81651088 -0.79699432]\n",
      " [17.48154215 -0.79376716]\n",
      " [17.99795341 -0.79905679]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  262\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.72596287727356\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [19.65070346 -0.79929348]\n",
      " [21.81651088 -0.79699432]\n",
      " [17.48154215 -0.79376716]\n",
      " [18.47463841 -0.79915111]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  263\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  16\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.843935251235962\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [19.65070346 -0.79929348]\n",
      " [21.81651088 -0.79699432]\n",
      " [17.48154215 -0.79376716]\n",
      " [18.63195028 -0.799236  ]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  264\n",
      "action_current_episode = [0, 0, 0, 0, 0, 1]\n",
      "count_step =  6\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.770601511001587\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [19.65070346 -0.79929348]\n",
      " [21.81651088 -0.79699432]\n",
      " [17.48154215 -0.79376716]\n",
      " [18.88201813 -0.7993124 ]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  265\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  9\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.587044954299927\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [19.68105276 -0.79936413]\n",
      " [21.81651088 -0.79699432]\n",
      " [17.48154215 -0.79376716]\n",
      " [18.88201813 -0.7993124 ]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  266\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.572214365005493\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [19.68105276 -0.79936413]\n",
      " [21.92907585 -0.79729489]\n",
      " [17.48154215 -0.79376716]\n",
      " [18.88201813 -0.7993124 ]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  267\n",
      "action_current_episode = [0, 0, 0, 0, 1]\n",
      "count_step =  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.672162294387817\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [19.68105276 -0.79936413]\n",
      " [21.92907585 -0.79729489]\n",
      " [17.48154215 -0.79376716]\n",
      " [19.28413357 -0.79938116]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  268\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  14\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  6.748387575149536\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [20.22217966 -0.79942772]\n",
      " [21.92907585 -0.79729489]\n",
      " [17.48154215 -0.79376716]\n",
      " [19.28413357 -0.79938116]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  269\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  19\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.680951356887817\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [20.22217966 -0.79942772]\n",
      " [21.92907585 -0.79729489]\n",
      " [17.48154215 -0.79376716]\n",
      " [19.34553459 -0.79944304]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  270\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  6.800475358963013\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [20.22217966 -0.79942772]\n",
      " [24.32058282 -0.7975654 ]\n",
      " [17.48154215 -0.79376716]\n",
      " [19.34553459 -0.79944304]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  271\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  90\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.823442697525024\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [20.22217966 -0.79942772]\n",
      " [24.32058282 -0.7975654 ]\n",
      " [19.00630347 -0.79439045]\n",
      " [19.34553459 -0.79944304]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  272\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  49\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  6.902220010757446\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [20.22217966 -0.79942772]\n",
      " [24.32058282 -0.7975654 ]\n",
      " [19.00630347 -0.79439045]\n",
      " [20.45957011 -0.79949874]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  273\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  38\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  6.658207178115845\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 6.09808408 -0.64410509]\n",
      " [20.22217966 -0.79942772]\n",
      " [24.32058282 -0.7975654 ]\n",
      " [19.03729717 -0.7949514 ]\n",
      " [20.45957011 -0.79949874]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  274\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "LOOP START :0.0\n",
      "8.7\n",
      "DISTANCE FOR REWARD :  8.731682062149048\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.05726199 -0.79942772]\n",
      " [24.32058282 -0.7975654 ]\n",
      " [19.03729717 -0.7949514 ]\n",
      " [20.45957011 -0.79949874]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  275\n",
      "action_current_episode = [0]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  2.0035688877105713\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.05726199 -0.79942772]\n",
      " [24.32058282 -0.7975654 ]\n",
      " [19.65070346 -0.56545626]\n",
      " [20.45957011 -0.79949874]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  276\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  21\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  2.1236112117767334\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.05726199 -0.79942772]\n",
      " [24.32058282 -0.7975654 ]\n",
      " [20.04288573 -0.46391064]\n",
      " [20.45957011 -0.79949874]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  277\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  2.1858465671539307\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.05726199 -0.79942772]\n",
      " [24.32058282 -0.7975654 ]\n",
      " [20.34111239 -0.37251957]\n",
      " [20.45957011 -0.79949874]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  278\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  11\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  2.1368157863616943\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.05726199 -0.79942772]\n",
      " [24.37191597 -0.67280886]\n",
      " [20.34111239 -0.37251957]\n",
      " [20.45957011 -0.79949874]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  279\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  2.073045015335083\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.05726199 -0.79942772]\n",
      " [26.64894298 -0.56052797]\n",
      " [20.34111239 -0.37251957]\n",
      " [20.45957011 -0.79949874]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  280\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  94\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  2.0274722576141357\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.05726199 -0.79942772]\n",
      " [26.64894298 -0.56052797]\n",
      " [20.34111239 -0.37251957]\n",
      " [20.51862142 -0.67454886]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  281\n",
      "action_current_episode = [0, 0, 1]\n",
      "count_step =  3\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  2.1514546871185303\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.05726199 -0.79942772]\n",
      " [26.99676757 -0.45947518]\n",
      " [20.34111239 -0.37251957]\n",
      " [20.51862142 -0.67454886]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  282\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  16\n",
      "LOOP START :0.0\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "8.8\n",
      "DISTANCE FOR REWARD :  2.1059863567352295\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.64381975 -0.67448495]\n",
      " [26.99676757 -0.45947518]\n",
      " [20.34111239 -0.37251957]\n",
      " [20.51862142 -0.67454886]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  283\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  23\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  2.029756784439087\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.64381975 -0.67448495]\n",
      " [26.99676757 -0.45947518]\n",
      " [21.01581537 -0.29026762]\n",
      " [20.51862142 -0.67454886]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  284\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  24\n",
      "LOOP START :0.0009975433349609375\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  2.042755365371704\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.64381975 -0.67448495]\n",
      " [27.0197708  -0.36852766]\n",
      " [21.01581537 -0.29026762]\n",
      " [20.51862142 -0.67454886]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  285\n",
      "action_current_episode = [0, 1]\n",
      "count_step =  2\n",
      "LOOP START :0.0\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "9.1\n",
      "DISTANCE FOR REWARD :  2.192952871322632\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.64381975 -0.67448495]\n",
      " [27.0197708  -0.36852766]\n",
      " [21.01581537 -0.29026762]\n",
      " [20.75364862 -0.56209398]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  286\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  9\n",
      "LOOP START :0.0\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "8.9\n",
      "DISTANCE FOR REWARD :  2.3433315753936768\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.64381975 -0.67448495]\n",
      " [27.20297047 -0.28667489]\n",
      " [21.01581537 -0.29026762]\n",
      " [20.75364862 -0.56209398]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  287\n",
      "action_current_episode = [0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "count_step =  9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOP START :0.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "9.0\n",
      "LOOP START :0.0\n",
      "7.2\n",
      "LOOP START :0.0\n",
      "8.5\n",
      "LOOP START :0.0\n",
      "6.9\n",
      "DISTANCE FOR REWARD :  6.872177362442017\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [-0.08        0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.64381975 -0.67448495]\n",
      " [27.20297047 -0.28667489]\n",
      " [23.77533736 -0.29026762]\n",
      " [20.75364862 -0.56209398]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  288\n",
      "action_current_episode = [0]\n",
      "count_step =  1\n",
      "LOOP START :1.1205673217773438e-05\n",
      "7.2\n",
      "LOOP START :0.0\n",
      "9.0\n",
      "DISTANCE FOR REWARD :  9.027140855789185\n",
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [-0.08        0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.64381975 -0.67448495]\n",
      " [27.20297047 -0.28667489]\n",
      " [23.45156202 -0.29026762]\n",
      " [20.75364862 -0.56209398]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "episode number =  289\n",
      "action_current_episode = [0]\n",
      "count_step =  1\n",
      "LOOP START :0.0\n",
      "27.3\n",
      "LOOP START :0.0\n",
      "4.1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Spawn failed because of collision at spawn position",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9ca096f4645d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepisode_start\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-62f4d1b35544>\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcarla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcarla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLocation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m125\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcarla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvehicle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspawn_actor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvehicle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Spawn failed because of collision at spawn position"
     ]
    }
   ],
   "source": [
    "env = CarEnv()\n",
    "\n",
    "# action มี 2 อันคือ เบรคและเร่งเต็มที่, state มี 13 อัน คือ ชน, 0-1, 1-2, 2-3, 3-4, 4-5, 5-6, 6-7, 7-8, 8-9, 9-10, 10-11, >11\n",
    "action_space_size = 2\n",
    "state_space_size = 10\n",
    "#q_table = np.zeros((state_space_size, action_space_size))\n",
    "q_table = []\n",
    "dist_q=[]\n",
    "\n",
    "num_episodes = 300\n",
    "max_steps_per_episode = 100\n",
    "learning_rate = 0.1\n",
    "discount_rate = 0.99\n",
    "\n",
    "exploration_rate = 1\n",
    "max_exploration_rate = 1\n",
    "min_exploration_rate = 0.01\n",
    "exploration_decay_rate = 0.01\n",
    "\n",
    "count = 0\n",
    "rewards_all_episodes = []\n",
    "action_all_episodes = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()\n",
    "      \n",
    "    ss=time.time()-env.episode_start\n",
    "    print('LOOP START :'+str(ss))\n",
    "    done = False\n",
    "    rewards_current_episode = []\n",
    "    action_current_episode = []\n",
    "    count_step=0\n",
    "    \n",
    "    for step in range(max_steps_per_episode):\n",
    "        print(state)\n",
    "        exploration_rate_threshold = random.uniform(0, 1)\n",
    "        if exploration_rate_threshold > exploration_rate:\n",
    "            #action = np.argmax(q_table[state,:]) \n",
    "            #print('YEAH')\n",
    "            if state not in dist_q:\n",
    "                break\n",
    "            action=q_table[dist_q.index(state)].index(max(q_table[dist_q.index(state)][:]))\n",
    "        else:\n",
    "            #print('DAMN_BRO')\n",
    "            action = np.random.randint(0, high=2, size=None, dtype='int')\n",
    "        action_current_episode.append(action)\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        update_q(state,new_state,action,reward)\n",
    "        count_step+=1\n",
    "        state = new_state\n",
    "        rewards_current_episode.append(reward)\n",
    "                    \n",
    "        if done == True:\n",
    "            print(np.array(q_table))\n",
    "            #print('destroying actors')\n",
    "            for actor in env.actor_list:\n",
    "                actor.destroy()\n",
    "            count+=1\n",
    "            print('episode number = ',count)\n",
    "            #print('distance to obstacle = ',state)\n",
    "            #print('rewards_current_episode = ',rewards_current_episode)\n",
    "            print('action_current_episode =', action_current_episode)\n",
    "            print('count_step = ', count_step)\n",
    "            break            \n",
    "        \n",
    "    # Exploration rate decay\n",
    "    exploration_rate = min_exploration_rate + \\\n",
    "          (max_exploration_rate - min_exploration_rate) * np.exp(-exploration_decay_rate*episode)\n",
    "    #print('exploration rate: '+str(exploration_rate))\n",
    "\n",
    "    rewards_all_episodes.append(rewards_current_episode)\n",
    "    action_all_episodes.append(action_current_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.6"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[dist_q.index(state)].index(max(q_table[dist_q.index(state)][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [-0.08        0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 5.79198599 -0.64410509]\n",
      " [23.64381975 -0.67448495]\n",
      " [27.20297047 -0.28667489]\n",
      " [23.45156202 -0.29026762]\n",
      " [20.75364862 -0.56209398]\n",
      " [ 0.54725823 -0.2168    ]\n",
      " [ 0.         -0.08      ]]\n",
      "[2.  2.1 2.2 2.3 6.  6.1 6.2 6.3 6.5 6.6 6.7 6.8 6.9 7.  7.1 8.7 8.8 8.9\n",
      " 9.  9.1 9.2 9.3]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(q_table))\n",
    "print(np.array(dist_q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 : -0.3999999999999999\n",
      "20 : -0.7499999999999998\n",
      "30 : -0.9199999999999999\n",
      "40 : -0.9700000000000006\n",
      "50 : -0.7200000000000008\n",
      "60 : -0.4200000000000007\n",
      "70 : -0.12000000000000058\n",
      "80 : -0.39000000000000046\n",
      "90 : 0.4599999999999995\n",
      "100 : 1.5599999999999992\n",
      "110 : 2.209999999999998\n",
      "120 : 4.3599999999999985\n",
      "130 : 7.560000000000002\n",
      "140 : 11.410000000000005\n",
      "150 : 14.610000000000003\n",
      "160 : 18.55999999999999\n",
      "170 : 23.42499999999998\n",
      "180 : 27.274999999999967\n",
      "190 : 30.024999999999956\n",
      "200 : 37.87499999999994\n",
      "210 : 41.47499999999993\n",
      "220 : 48.87499999999992\n",
      "230 : 55.22499999999995\n",
      "240 : 63.375\n",
      "250 : 72.97500000000005\n",
      "260 : 81.1750000000001\n",
      "270 : 86.07500000000013\n",
      "280 : 101.74000000000017\n",
      "290 : 115.7000000000002\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a=rewards_all_episodes\n",
    "n = 0 \n",
    "count = 0\n",
    "n_list=[]\n",
    "count_list=[]\n",
    "for i in a :\n",
    "    for j in i:\n",
    "        count += j\n",
    "    count_list.append(sum(i))\n",
    "    n+=1\n",
    "    n_list.append(n)\n",
    "    if n%10 == 0:\n",
    "        print(n,':',str(count/10)) \n",
    "        \n",
    "ax=plt.scatter(n_list,count_list,marker='o')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 1, 3, 1, 1, 5, 1, 2, 1, 4, 1, 4, 1, 2, 1, 2, 1, 2, 1, 5, 3, 1, 1, 3, 1, 3, 3, 3, 1, 3, 2, 3, 4, 3, 4, 1, 2, 2, 3, 3, 2, 6, 3, 7, 1, 1, 4, 1, 1, 1, 1, 9, 4, 3, 3, 1, 7, 2, 1, 1, 8, 3, 1, 1, 7, 1, 1, 8, 3, 1, 2, 1, 5, 2, 4, 1, 2, 1, 7, 2, 3, 1, 2, 13, 2, 1, 4, 8, 3, 1, 4, 7, 10, 9, 9, 3, 1, 1, 2, 4, 5, 1, 4, 3, 4, 4, 4, 8, 3, 2, 2, 1, 1, 1, 8, 23, 18, 10, 11, 4, 15, 1, 16, 3, 9, 15, 3, 13, 1, 6, 31, 6, 1, 10, 1, 17, 4, 26, 5, 3, 12, 5, 2, 19, 1, 1, 32, 10, 24, 1, 4, 14, 28, 4, 1, 6, 21, 2, 1, 17, 11, 29, 3, 5, 18, 15, 5, 18, 48, 5, 2, 7, 18, 2, 1, 8, 5, 7, 3, 23, 3, 2, 5, 28, 2, 4, 2, 9, 30, 22, 3, 6, 13, 14, 8, 38, 16, 33, 18, 16, 6, 17, 21, 3, 5, 1, 8, 3, 2, 2, 42, 42, 36, 4, 3, 2, 34, 7, 4, 19, 33, 1, 12, 31, 16, 21, 15, 1, 10, 9, 66, 51, 9, 3, 10, 13, 5, 13, 15, 9, 16, 35, 69, 54, 1, 12, 1, 6, 15, 16, 9, 68, 12, 36, 10, 14, 7, 3, 45, 5, 16, 6, 9, 2, 5, 14, 19, 3, 90, 49, 38, 2, 100, 1, 21, 14, 11, 3, 94, 3, 16, 23, 24, 2, 9, 9, 100, 0, 0, 1, 0, 1, 0, 0]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296]\n"
     ]
    }
   ],
   "source": [
    "b=action_all_episodes\n",
    "step = []\n",
    "episode=[]\n",
    "n=1\n",
    "for i in b:\n",
    "    step.append(len(i))\n",
    "    episode.append(n)\n",
    "    n+=1\n",
    "print(step)\n",
    "print(episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=plt.scatter(episode,step,marker='o')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Step_per_episode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.349251  ,  0.20832748],\n",
       "       [ 1.77224689, -0.73807624],\n",
       "       [ 0.99055676, -0.59842658],\n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 0.        , -0.06542415],\n",
       "       [27.15730793, -0.6529352 ],\n",
       "       [34.00748832, -0.65424151],\n",
       "       [ 1.71618289,  0.06933105],\n",
       "       [49.99300531,  1.96897879],\n",
       "       [49.37267201,  0.27837086]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133.38019801314636"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.uniform(110,150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.2, 0.3, 0.4, 0.5]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
