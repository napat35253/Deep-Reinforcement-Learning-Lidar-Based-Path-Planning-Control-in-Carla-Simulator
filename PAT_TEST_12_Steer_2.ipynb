{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT DONE\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import datetime\n",
    "from scipy.spatial import cKDTree as kdtree\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.models import model_from_json\n",
    "import pandas as pd\n",
    "from plotnine import *\n",
    "from jupyterplot import ProgressPlot\n",
    "#from keras.callbacks import TensorBoard\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as backend\n",
    "from threading import Thread\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "try:\n",
    "    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "import carla\n",
    "print('IMPORT DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Environment [Action/Reward here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarEnv:\n",
    "    global town\n",
    "    #BRAKE_AMT = 1.0\n",
    "    actor_list = []\n",
    "    collision_hist = []\n",
    "    pt_cloud = []\n",
    "    pt_cloud_filtered = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.client = carla.Client('localhost', 2000)\n",
    "        self.client.set_timeout(2.0)\n",
    "        world = self.client.load_world(town)\n",
    "        self.world = self.client.get_world()\n",
    "        blueprint_library = self.world.get_blueprint_library()\n",
    "        self.model_3 = blueprint_library.filter('model3')[0]\n",
    "        self.truck_2 = blueprint_library.filter('carlamotors')[0]\n",
    "        self.place=0\n",
    "        \n",
    "        spectator = self.world.get_spectator()\n",
    "        spectator.set_transform(carla.Transform(carla.Location(249,-120,3), carla.Rotation(yaw=-90)))\n",
    "        \n",
    "        #spawn a vehicle\n",
    "        blueprint_library = self.world.get_blueprint_library()\n",
    "        self.Isetta = blueprint_library.filter('Isetta')[0]\n",
    "        \n",
    "        \n",
    "    def Black_screen(self):\n",
    "        settings = self.world.get_settings()\n",
    "        settings.no_rendering_mode = True\n",
    "        self.world.apply_settings(settings)\n",
    "    \n",
    "    def set_location(self,x,y):\n",
    "        \n",
    "        self.lo_x,self.lo_y=x,y\n",
    "        self.place=x,y\n",
    "        \n",
    "    def get_distance(self):\n",
    "        l=self.vehicle.get_location()\n",
    "        current_location=[l.x,l.y]\n",
    "        dist,indice=kd_tree_map.query(current_location,1)\n",
    "        return dist\n",
    "    def get_location(self):\n",
    "        l=self.vehicle.get_location()\n",
    "        current_location=[l.x,l.y]\n",
    "        return current_location\n",
    "                     \n",
    "    def reset(self):\n",
    "        self.collision_hist = []\n",
    "        self.actor_list = []\n",
    "        self.pt_cloud = []\n",
    "        self.pt_cloud_filtered = []\n",
    "        \n",
    "        ##print('Location: ',str(place))\n",
    "        #transform = carla.Transform(carla.Location(-120,place,3),carla.Rotation(0,-90,0))\n",
    "        if self.place == 0:\n",
    "            transform = carla.Transform(carla.Location(249,-130,0.1),carla.Rotation(0,-90,0)) \n",
    "        else :\n",
    "            transform = carla.Transform(carla.Location(self.lo_x,self.lo_y),carla.Rotation(0,-90,0))  \n",
    "            \n",
    "        self.flag = 0\n",
    "        self.vehicle = self.world.spawn_actor(self.Isetta, transform)\n",
    "        self.flag = 1\n",
    "        \n",
    "        self.actor_list.append(self.vehicle)\n",
    "     \n",
    "\n",
    "        self.lidar_sensor = self.world.get_blueprint_library().find('sensor.lidar.ray_cast')\n",
    "        self.lidar_sensor.set_attribute('points_per_second', '100000')\n",
    "        self.lidar_sensor.set_attribute('channels', '32')\n",
    "        self.lidar_sensor.set_attribute('range', '10000')\n",
    "        self.lidar_sensor.set_attribute('upper_fov', '10')\n",
    "        self.lidar_sensor.set_attribute('lower_fov', '-10')\n",
    "        self.lidar_sensor.set_attribute('rotation_frequency', '60')\n",
    "        \n",
    "        transform = carla.Transform(carla.Location(x=0, z=1.9))\n",
    "        time.sleep(0.01)\n",
    "\n",
    "        self.sensor = self.world.spawn_actor(self.lidar_sensor, transform, attach_to=self.vehicle)\n",
    "     \n",
    "        self.actor_list.append(self.sensor)\n",
    "        self.sensor.listen(lambda data: self.process_lidar(data))\n",
    "\n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, brake=0.0))\n",
    "        self.episode_start = time.time()\n",
    "   \n",
    "        time.sleep(0.4) # sleep to get things started and to not detect a collision when the car spawns/falls from sky.\n",
    "        \n",
    "        transform2 = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "        colsensor = self.world.get_blueprint_library().find('sensor.other.collision')\n",
    "        self.colsensor = self.world.spawn_actor(colsensor, transform2, attach_to=self.vehicle)\n",
    "        self.actor_list.append(self.colsensor)\n",
    "        self.colsensor.listen(lambda event: self.collision_data(event))\n",
    "\n",
    "        while self.distance_to_obstacle_f is None:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        self.episode_start = time.time()\n",
    "        \n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, brake=0.0))\n",
    "        ref_map=self.get_distance()\n",
    "        ##SENSOR LIDAR\n",
    "        xx = self.distance_to_obstacle_f\n",
    "        yy = self.distance_to_obstacle_r\n",
    "        zz = self.distance_to_obstacle_l\n",
    "        state_=np.array([xx,yy,zz,ref_map])\n",
    "        \n",
    "        return state_\n",
    "\n",
    "    def collision_data(self, event):\n",
    "        self.collision_hist.append(event)\n",
    "\n",
    "    def process_lidar(self, raw):\n",
    "        points = np.frombuffer(raw.raw_data, dtype=np.dtype('f4'))\n",
    "        points = np.reshape(points, (int(points.shape[0] / 3), 3))*np.array([1,-1,-1])\n",
    "        \n",
    "        lidar_f = lidar_line(points,90,2)\n",
    "        lidar_r = lidar_line(points,45,2)\n",
    "        lidar_l = lidar_line(points,135,2)\n",
    "\n",
    "        if len(lidar_f) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            self.distance_to_obstacle_f = min(lidar_f[:,1])-2.247148275375366\n",
    "        \n",
    "        if len(lidar_r) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            self.distance_to_obstacle_r = np.sqrt(min(lidar_r[:,0]**2 + lidar_r[:,1]**2))\n",
    "        \n",
    "        if len(lidar_l) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            self.distance_to_obstacle_l = np.sqrt(min(lidar_l[:,0]**2 + lidar_l[:,1]**2))\n",
    "    \n",
    "\n",
    "    def step(self, action):\n",
    "        global sleepy,steer_\n",
    "        \n",
    "        ref_map=self.get_distance()\n",
    "        \n",
    "        set_reward=3-ref_map\n",
    "        \n",
    "        if action == 0:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, brake=0.0, steer = 0))\n",
    "            time.sleep(sleepy)\n",
    "            steer_+=0\n",
    "            reward = set_reward\n",
    "        elif action == 1:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, brake=0.0, steer = 0.1))\n",
    "            time.sleep(sleepy)\n",
    "            steer_+=0.1\n",
    "            reward = set_reward\n",
    "        elif action == 2:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, brake=0.0, steer = -0.1))\n",
    "            time.sleep(sleepy)\n",
    "            steer_+=-0.1\n",
    "            reward = set_reward\n",
    "        elif action == 3:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, brake=0.0, steer = 0.3))\n",
    "            time.sleep(sleepy)\n",
    "            steer_+=0.3\n",
    "            reward = set_reward\n",
    "        elif action == 4:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, brake=0.0, steer = -0.3))\n",
    "            time.sleep(sleepy)\n",
    "            steer_+=-0.3\n",
    "            reward = set_reward\n",
    " \n",
    "\n",
    "        \n",
    "        if len(self.collision_hist) != 0:\n",
    "            done = True\n",
    "        else :\n",
    "            done=False\n",
    "            \n",
    "        if self.episode_start + SECONDS_PER_EPISODE < time.time():\n",
    "            done = True\n",
    "            \n",
    "        xx = self.distance_to_obstacle_f\n",
    "        yy = self.distance_to_obstacle_r\n",
    "        zz = self.distance_to_obstacle_l\n",
    "        state_=np.array([xx,yy,zz,ref_map])\n",
    "            \n",
    "        return state_, reward, done, None\n",
    "    \n",
    "    def test_step(self,steer,sleepy):\n",
    "        ref_map=self.get_distance()\n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, brake=0.0, steer = steer))\n",
    "        time.sleep(sleepy)\n",
    "        reward = 1\n",
    "        \n",
    "        if len(self.collision_hist) != 0:\n",
    "            done = True\n",
    "        else :\n",
    "            done=False\n",
    "        \n",
    "        if self.episode_start + SECONDS_PER_EPISODE < time.time():\n",
    "            done = True\n",
    "            \n",
    "        xx = self.distance_to_obstacle_f\n",
    "        yy = self.distance_to_obstacle_r\n",
    "        zz = self.distance_to_obstacle_l\n",
    "        state_=np.array([xx,yy,zz,ref_map])\n",
    "            \n",
    "        return state_, reward, done, None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_carla(require):\n",
    "    try:\n",
    "        if require == 'fast':\n",
    "            os.popen('C:\\\\Users\\\\nbhah\\\\Desktop\\\\Carla\\\\CarlaUE4\\\\Binaries\\\\Win64\\\\CarlaUE4.exe -benchmark  -fps=10 -quality-level=Low')\n",
    "        else:\n",
    "            os.popen('C:\\\\Users\\\\nbhah\\\\Desktop\\\\Carla\\\\CarlaUE4\\\\Binaries\\\\Win64\\\\CarlaUE4.exe')\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "    print('opening Carla')\n",
    "    \n",
    "def close_carla():\n",
    "    try:\n",
    "        os.system('TASKKILL /F /IM CarlaUE4.exe')\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "def carla_is_running():\n",
    "    import psutil    \n",
    "    if \"CarlaUE4.exe\" in (p.name() for p in psutil.process_iter()):\n",
    "        return True\n",
    "    \n",
    "def xxx():\n",
    "    env.world.wait_for_tick()\n",
    "    for x in list(env.world.get_actors()):\n",
    "        if x.type_id == 'vehicle.tesla.model3' or x.type_id == 'sensor.lidar.ray_cast' or x.type_id == 'sensor.other.collision':\n",
    "            x.destroy()\n",
    "            \n",
    "def lidar_line(points,degree,width):\n",
    "    angle = degree*(2*np.pi)/360\n",
    "    points_l = points\n",
    "    points_l = points_l[np.logical_and(points_l[:,2] > -1.75, points_l[:,2] < 1000)] #z\n",
    "    points_l = points_l[np.logical_and(np.tan(angle)*points_l[:,0]+width*np.sqrt(1+np.tan(angle)**2)>=points_l[:,1], np.tan(angle)*points_l[:,0]-width*np.sqrt(1+np.tan(angle)**2)<=points_l[:,1])] #y\n",
    "    if 180>degree >0:\n",
    "        points_l = points_l[np.logical_and(points_l[:,1]>0, points_l[:,1]<1000)] #y>0\n",
    "    if 180<degree<360:\n",
    "        points_l = points_l[np.logical_and(points_l[:,1]<0, points_l[:,1] > -1000)] #x\n",
    "    if degree == 0 or degree == 360:\n",
    "        points_l = points_l[np.logical_and(points_l[:,0]>0,points_l[:,0] <1000 )] #x\n",
    "    if degree == 180:\n",
    "        points_l = points_l[np.logical_and(points_l[:,0] >-1000 , points_l[:,0]<0 )]\n",
    "    return  points_l\n",
    "\n",
    "map=pd.read_csv('DATA\\map_straight.csv')\n",
    "kd_tree_map=kdtree(map.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAGuCAYAAACX/tJnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU9b3/8fesSRgykpCQgJgQLBRZXG5RpGoRBaWuxah4FVur2JpKa6+2ysOlogJtbbULoCAoggXKvcKlVqtet1I1ym1trwREpJAQEQIEQxOyTWb5/cGPkZMJyUwymTMz5/V8PPpov98zmfmc6Scnb85qC4VCIQEAAFiM3ewCAAAAzEAIAgAAlkQIAgAAlkQIAgAAlkQIAgAAlkQIAgAAlkQIAgAAlkQIAgAAluQ0u4BkVltbG5f3sdlsysrKUnNzs7g3ZXTcbrd8Pp/ZZaQMeix29Fj06K/uoceiF+8ey8vLi+p17AlKALvdrj59+shu5+uOVkZGhtklpBR6LHb0WPTor+6hx6JnVo/R0QAAwJIIQQAAwJIIQQAAwJIIQQAAwJIIQQAAwJIIQQAAwJIIQQAAwJIIQQAAwJIIQQAAwJIIQQAAwJJS4tlhmzZt0po1a7Rjxw653W6tWLEivKytrU2LFi3Shx9+qIaGBuXl5emaa67R+eefH37Nrl27NH/+fFVVVamwsFBlZWUaNWqUCWsCAACSRUrsCcrMzNSkSZN08803RywLBALKzc3VnDlztHr1at1+++1atGiRPv74Y0mS3+/XnDlzNH78eK1evVqlpaWaO3euDh8+nOjVAAAASSQlQtDw4cM1ceJEDRw4MGJZZmambrjhBhUWFsput2vkyJE65ZRTtHXrVklSRUWFWltbNXXqVLlcLk2cOFEFBQUqLy9P9GoAAIAkkhIhKBYtLS365z//qeLiYklSdXW1iouLDU+mLSkpUXV1tVklAgCQtj755BPdfffdmj9/vvx+v9nldMr0c4ICgUCnyx0OR9TvFQqF9Jvf/EbDhg3TGWecIUlqbm6Wx+MxvM7j8aipqSni52tra1VbWxse2+125efnR/35x3N0HWJZF6uz2Wx8XzGgx2JHj0WP/uoeK/ZYMBjUlVdeqbq6OtlsNtntdv3gBz/o8ufM6jHTQ9ADDzygzZs3d7isX79+hpOgOxMKhfTEE0/o4MGDevjhh2Wz2SRJWVlZEYGnqalJWVlZEe+xdu1aLVmyJDy+6aabNHPmzGhXpUterzdu72UFbrfb7BJSDj0WG3osNvRX7KzWYy0tLTp48KBCoZAcDof279+vnJycqH8+0T1megiaN29ej98jFApp0aJF2rlzpx555BFlZmaGlxUVFWndunUKBoPhQ2KVlZWaMmVKxPuUlpZqwoQJ4bHdblddXV2P63M4HPJ6vaqvr+9yzxeO8Hg8amxsNLuMlEGPxY4eix791T1W7bF77rlHP//5z9W/f39985vfjOrvaLx7LNrgZXoIikYwGJTf7w8fW/T5fLLZbHK5XJKkxYsXa9u2bZozZ4769Olj+NkxY8bI5XJp/fr1uvzyy1VeXq6amhqNHz8+4nPy8vKUl5cXHtfW1sb1Fz4QCLABiVIoFOK76gZ6LHr0WOzor9hYtcfuuusuzZw5Uy6XS3a7PabvINE9ZguFQqGEfVo3VVRU6L777jPMDRgwQEuXLtX+/fs1Y8YMuVwuw7HEq6++Wtdee60kqaqqSgsWLFBVVZUKCgpUVlam0aNHd/m5x54f1BMOh0M5OTmqq6uz5C9Ed2RnZ6uhocHsMlIGPRY7eix69Ff30GPRi3ePHbtDozMpEYLMQggyDxuP2NBjsaPHokd/dQ89Fj2zQlDaXSIPAAAQDUIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJEIQAACwJKfZBQAAAGvJz883jD///HNT6mBPEAAAsCRbKBQKmV1Esqqvr1dGRkaP38dms8ntdsvn84mvOzpOp1N+v9/sMlIGPRY7eix69Ff30GPHl5mZaRi3trbGtcei/dvN4bBO+Hw++Xy+Hr+Pw+GQ2+1WY2OjAoFAHCpLf9nZ2WpoaDC7jJRBj8WOHose/dU99Fj0Ghsb49pj0YYgDocBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLIgQBAABLcppdQDQ2bdqkNWvWaMeOHXK73VqxYkWHr6uvr1dZWZkGDhyoX/7yl+H5Xbt2af78+aqqqlJhYaHKyso0atSoRJUPAACSUErsCcrMzNSkSZN08803d/q6Z555RkOGDDHM+f1+zZkzR+PHj9fq1atVWlqquXPn6vDhw71YMQAASHYpEYKGDx+uiRMnauDAgcd9TUVFhWpqajRx4sSI+dbWVk2dOlUul0sTJ05UQUGBysvLe7tsAACQxFIiBHWlra1Nixcv1m233SabzWZYVl1dreLiYtntX6xqSUmJqqurE10mAABIIqafExQIBDpd7nA4unyP//qv/9IZZ5yhIUOGaMeOHYZlzc3N8ng8hjmPx6OmpqaI96mtrVVtbW14bLfblZ+f3+Xnd+XoOkSzLjjCZrPxfcWAHosdPRY9+qt76LHomdVjpoegBx54QJs3b+5wWb9+/Y57EvRRe/bs0Z///Gf95je/6XB5VlZWROBpampSVlZWxGvXrl2rJUuWhMc33XSTZs6c2dUqRM3r9cbtvazA7XabXULKocdiQ4/Fhv6KHT0WnaO9legeMz0EzZs3r0c/v3XrVh08eFAzZsyQdOREaJ/PpxtuuEFLlixRUVGR1q1bp2AwGD4kVllZqSlTpkS8V2lpqSZMmBAe2+121dXV9ag+6Uiy9Xq9qq+v73LPF47weDxqbGw0u4yUQY/Fjh6LHv3VPfRYx4LBYMRcfX19XHssJycnqteZHoKiEQwG5ff75ff7JUk+n082m00ul0vnnnuuTjvttPBr3333Xb311lu6//77lZWVpTFjxsjlcmn9+vW6/PLLVV5erpqaGo0fPz7ic/Ly8pSXlxce19bWxvUXPhAIsAGJUigU4rvqBnosevRY7Oiv2NBjHevoOzk6l+geS4kQtGXLFt13333h8dVXX60BAwZo6dKlysjIUEZGRnhZ37595XQ6w2HG6XTq/vvv14IFC7Rq1SoVFBTo3nvvVXZ2dsLXAwAAGLW/oCmhnx0KhUKmfXqSO/Yk6Z5wOBzKyclRXV0d/yqIUnZ2thoaGswuI2XQY7Gjx6JHf3UPPdaxtrY2DRo0KDx2OBw6cOBAXHvs2KM6nUmLS+QBAEBqOvYWNgn/bNM+GQAAWI7P5zOMj57vawZCEAAASBgzQ097hCAAAJAw7c/54XAYAACwhLa2NrNLCCMEAQCAhGlpaTG7hDBCEAAASJjW1lazSwgjBAEAgISpr683u4QwQhAAAEiY9ucEJfrJ8cciBAEAgIRpf4m8y+UyqRJCEAAASKD2h8O4RB4AAFhCXV2d2SWEEYIAAEDC/Otf/zKM2RMEAAAsoaGhwTDmnCAAAGAJ7fcEEYIAAIAl7N+/3zDmEnkAAGAJ7Q+HZWVlmVQJIQgAACRQc3OzYZyTk2NSJYQgAACQQO0foEoIAgAAltDY2GgYFxQUmFQJIQgAACRQ+ztGZ2dnm1QJIQgAACRQ+3OCBg4caFIlhCAAAJBA7R+gWlRUZFIlhCAAAJBAPp/PMB46dKhJlRCCAABAArXfEzRgwACTKiEEAQAAE/Xr18+0zyYEAQAA09hsNtM+mxAEAAAsiRAEAAAsiRAEAAAsiRAEAAASoqmpyewSDAhBAAAgIT755BPD2OVymVTJEYQgAACQENu2bTOMs7KyTKrkCKepn57k3G63MjIyevw+Ry//83g8CoVCPX4/K3A6naY+VC/V0GOxo8eiR391Dz0WafPmzYZxbm6usrOzTesxQlAnfD5fxO29u8PhcMjtdquxsVGBQCAOlaW/7OxsNTQ0mF1GyqDHYkePRY/+6h56LFJFRYVhnJOTo4aGhrj3WLQ7MDgcBgAAEuKzzz4zjEtKSkyq5AhCEAAASIi6ujrD+LTTTjOpkiMIQQAAICFaWloM43PPPdekSo4gBAEAgIRof57tiBEjTKrkCEIQAABIiPZXfrndbpMqOYIQBAAALIkQBAAAel0wGDS7hAiEIAAA0Ot27dplGDud5t+qkBAEAAB63bvvvmsY5+TkmFTJFwhBAACg17300kuGcTI8UoQQBAAAel37h6cWFRWZVMkXCEEAAKDXtb9b9IUXXmhSJV8gBAEAgF7X1NRkGE+ZMsWkSr5ACAIAAL2u/SXyxcXFJlXyBUIQAABIOJvNZnYJhCAAANC7WltbzS6hQ4QgAADQq95++23DOCMjw6RKjAhBAACgV73++uuGcW5urkmVGBGCAABAr3rvvfcM41GjRplUiREhCAAA9KqqqirD+LzzzjOnkHYIQQAAoFe1v0fQpZdealIlRoQgAACQUMlwjyCJEAQAAHpR+5skJhNCEAAA6DWffPKJYWy3J0/0SJ5KAABA2vn9739vGGdnZ5tUSSRCEAAA6DV/+ctfDONhw4aZVEkkQhAAAOg17S+Pnzp1qjmFdIAQBAAAek1DQ4NhTAgCAACWlJ+fb3YJYYQgAADQK1paWswuoVOEIAAA0CtefPFFwzhZnh5/lNPsAqKxadMmrVmzRjt27JDb7daKFSsiXlNeXq5Vq1Zp37598nq9uuWWW/TVr35VkrRr1y7Nnz9fVVVVKiwsVFlZWdI8vA0AgHT1wgsvGMaDBw82qZKOpcSeoMzMTE2aNEk333xzh8s//PBDLV26VN/73ve0Zs0aPfbYYxo6dKgkye/3a86cORo/frxWr16t0tJSzZ07V4cPH07kKgAAYDkffPCBYXzRRReZVEnHUiIEDR8+XBMnTtTAgQM7XL5q1SpNmzZNI0eOlN1uV79+/VRYWChJqqioUGtrq6ZOnSqXy6WJEyeqoKBA5eXliVwFAAAs58CBA4bx9ddfb1IlHUuJw2GdCQQC2r59u8aOHavvfOc78vl8Ou2003Trrbeqb9++qq6uVnFxseE23SUlJaqurjaxagAA0l8oFDKMR4wYYVIlHTM9BAUCgU6XOxyOTpcfOnRIfr9f77zzjubNm6fMzEw99thjWrJkif7jP/5Dzc3N8ng8hp/xeDxqamqKeK/a2lrV1taGx3a7PS6X8h1dh67WBV+w2Wx8XzGgx2JHj0WP/uoeq/dYR1eGHe/7MKvHTA9BDzzwgDZv3tzhsn79+nV4EvSxjp5pfumllyovL0+SdM0112jevHmSpKysrIjA09TUpKysrIj3Wrt2rZYsWRIe33TTTZo5c2b0K9MFr9cbt/eyArfbbXYJKYceiw09Fhv6K3ZW7rFXXnnFMPZ4PMrJyen0ZxLdY6aHoKNhpbv69u2rvLw82Wy2DpcXFRVp3bp1CgaD4UNilZWVmjJlSsRrS0tLNWHChPDYbrerrq6uR/VJR5Kt1+tVfX19l3u+cITH41FjY6PZZaQMeix29Fj06K/usXqPvfzyy4bxOeecc9y/qfHusa7C1lGmh6BoBINB+f1++f1+SZLP55PNZpPL5ZJ05Gzzl156SWPHjlVGRobWrl2rs846S5I0ZswYuVwurV+/XpdffrnKy8tVU1Oj8ePHR3xOXl5eeG+SdOTwWDx/4QOBABuQKIVCIb6rbqDHokePxY7+io3Ve6z9g1O//e1vd/l9JLrHbKH2Zy0loYqKCt13332GuQEDBmjp0qWSjnxpTz/9tP785z/L4XBo7NixuvXWW9WnTx9JRx7etmDBAlVVVamgoEBlZWUaPXp0l5977PlBPeFwOJSTk6O6ujpL/0LEIjs7O+J5Mzg+eix29Fj06K/usXqPFRQUKBgMhsc7d+5UdnZ2h6+Nd48du0OjMykRgsxCCDKP1TcesaLHYkePRY/+6h6r91j7C4vaXy5/LLNCUErcJwgAAKSOgwcPGsZOZ3KefUMIAgAAcfXPf/7TML7wwgtNqqRzhCAAABBXn376qeGq7RtvvNHEao6PEAQAAOJq+/bt4btFDxo0SF/72tdMrqhjhCAAABBXjz/+ePh/Hzx4sMMbFCeDboWgBQsW6NChQ/GuBQAApLj2V1b7fD6TKulat0LQPffco0GDBun666/Xm2++Ge+aAABAilq4cKFhnJuba1IlXetWCNq7d68ef/xx7dixQ5MmTdLQoUM1Z84c7d69O971AQCAFNL+TtHnnHOOSZV0rVshyOv16rbbbtPGjRu1adMmXXnllZo/f75KSkp0ySWXaO3atWpra4t3rQAAIMl99NFHhvE999xjUiVd6/GJ0aNHj9avfvUr/eMf/9A555yjV155Rddcc41OPPFEPfjgg2pubo5HnQAAIAUcfc7nUcOHDzepkq71KASFQiG9/PLLuvrqqzV06FB9/PHH+vGPf6zy8nLddtttmj9/vqZPnx6vWgEAQBKrrKw0u4SYdOs+1jt27NAzzzyjFStWaM+ePZo8ebJWrlypK6+8Mnxr7LPPPltjx47VddddF9eCAQBAcnrssccM4/bPD0s23QpBw4YN04knnqhvf/vbuuWWW1RcXNzh60aMGKFx48b1qEAAAJAaXnvtNcP4kksuMamS6HQrBP3hD3/QpZdeKru986Npw4cP11tvvdWtwgAAQGr5/PPPDePvf//7JlUSnW6FoMsvvzzedQAAgBTW/oRoScc9UpQseGwGAADosZdeeskwdjgcJlUSPUIQAADosfZ3iv7yl79sUiXRIwQBAIAeq6ioMIy/973vmVRJ9AhBAACgx9qfE3T11VebVEn0CEEAAKBHdu7cGTHHOUEAACDtzZs3zzBO9qvCjiIEAQCAHml/T8ArrrjCpEpiQwgCAAA9Ul9fbxj/4Ac/MKmS2BCCAABAt+3Zsydirl+/fiZUEjtCEAAA6LY5c+YYxn379jWpktgRggAAQLe98cYbhvGUKVNMqiR2hCAAANBt7R+aOnfuXJMqiR0hCAAAdMvevXsj5nJzc02opHsIQQAAoFt+9rOfGcapdD6QRAgCAADd1P7J8VdddZVJlXQPIQgAAHTLv/71L8N41qxZJlXSPYQgAAAQs+3bt0fM5efnm1BJ9xGCAABAzGbPnm0Yp9IJ0Uc5zS4gmbndbmVkZPT4fWw2myTJ4/EoFAr1+P2swOl0Kjs72+wyUgY9Fjt6LHr0V/eke49t2LDBML7tttu6vb5m9RghqBM+n08+n6/H7+NwOOR2u9XY2KhAIBCHytJfdna2GhoazC4jZdBjsaPHokd/dU8691goFFJra6th7rbbbuv2+sa7x6LdgcHhMAAAEJMXXnghYi4rK8uESnqGEAQAAGLS/q7QQ4YMMaeQHiIEAQCAmFRWVhrGDzzwgEmV9AwhCAAARK2j836uuOIKEyrpOUIQAACIWvu9Pi6Xy6RKeo4QBAAAovaHP/zBML7wwgtNqqTnCEEAACBqhw8fNowff/xxkyrpOUIQAACIyhtvvGEY22y2lHtUxrEIQQAAICr33nuvYfylL33JpErigxAEAACisnPnTsP4oYceMqmS+CAEAQCALn322WcRc5MnTzahkvghBAEAgC7NnDnTMI7HA8bNRggCAABdeu+99wzj66+/3qRK4ocQBAAAOtXS0hLxdPf2zw9LRYQgAADQqXnz5hnGTqczpe8UfRQhCAAAdGrZsmWG8cUXX2xSJfFFCAIAAMcVCoXU0tJimPvFL35hUjXxRQgCAADHtXTpUsM41e8SfSxCEAAAOK72zwYbN26cSZXEHyEIAAB0KBQKqba21jD35JNPmlRN/BGCAABAh1avXh0xN3jwYBMq6R2EIAAA0KGHH37YMB4zZoxJlfQOQhAAAIgQCoV08OBBw9wTTzxhUjW9gxAEAAAivPDCCxFzI0aMMKGS3kMIAgAAEWbNmmUYn3HGGSZV0nsIQQAAwKCjq8LS7VCYRAgCAADtLFmyJGLuS1/6kgmV9C5CEAAAMPjZz35mGI8dO9akSnoXIQgAAIQFg0E1NDQY5to/OiNdEIIAAEDYvHnzDGO73a4TTzzRpGp6FyEIAACEtT8BesqUKSZV0vucZhcQjU2bNmnNmjXasWOH3G63VqxYYVi+b98+LV68WB9//LEcDofOPPNMfec731FmZqYkadeuXZo/f76qqqpUWFiosrIyjRo1yoxVAQAgadXX16utrc0w96tf/cqkanpfSuwJyszM1KRJk3TzzTd3uPyJJ55Q3759tWzZMi1cuFCfffaZ1qxZI0ny+/2aM2eOxo8fr9WrV6u0tFRz587V4cOHE7kKAAAkvdtvv90wdjgcys3NNama3pcSIWj48OGaOHGiBg4c2OHympoafe1rX1NGRoa8Xq/OPvts7dq1S5JUUVGh1tZWTZ06VS6XSxMnTlRBQYHKy8sTuQoAACS9V1991TC+5ZZbTKokMVIiBHXliiuu0IYNG9TS0qJDhw7pvffeC1/OV11dreLiYtntX6xqSUmJqqurzSoXAICks3XrVoVCIcPcQw89ZFI1iWH6OUGBQKDT5Q6Ho8v3GDNmjN544w1dd911CgaDOvPMM3XRRRdJkpqbm+XxeAyv93g8ampqinif2tpawx0y7Xa78vPzo1mNTh1dh2jWBUfYbDa+rxjQY7Gjx6JHf3VPqvVY+70+ffv2VUZGRkI+26weMz0EPfDAA9q8eXOHy/r16xdxEnR7gUBAs2fP1qRJk/Szn/1Mfr9fS5Ys0eOPP667775bWVlZEYGnqalJWVlZEe+1du1aw10yb7rpJs2cObMba9Uxr9cbt/eyArfbbXYJKYceiw09Fhv6K3ap1GPbt283jH/7298qJycnoTUkusdMD0Ht70cQq8bGRtXW1uqyyy6T2+2W2+3WJZdcovvuu0+SVFRUpHXr1ikYDIYPiVVWVnZ4yV9paakmTJgQHtvtdtXV1fWoPulIsvV6vaqvr+9yzxeO8Hg8amxsNLuMlEGPxY4eix791T2p1GPPPvtsxNw3vvGNuPwNjEa8eyza8GZ6CIpGMBiU3++X3++XJPl8PtlsNrlcLnm9XhUWFupPf/qTSktLFQgE9Oqrr2rIkCGSjhwqc7lcWr9+vS6//HKVl5erpqZG48ePj/icvLw85eXlhce1tbVx/YUPBAJsQKIUCoX4rrqBHosePRY7+is2qdRjs2fPNoyHDBliSu2J7jFbqP1ZUEmooqIivGfnqAEDBoRv411ZWamnn35aO3fulCSNGDFCt956a/hqsqqqKi1YsEBVVVUqKChQWVmZRo8e3eXntn+Cbnc5HA7l5OSorq4uZX4hzJadnR1x23YcHz0WO3osevRX96RKjzU2NoZ3HBy1ceNGDR06NGE1xLvHjt2h0ZmUCEFmIQSZJ1U2HsmCHosdPRY9+qt7UqXHpk+fbrg03uVyac+ePQmtwawQlBaXyAMAgO5pf2+gb37zmyZVkniEIAAALOrtt9+OmJs7d64JlZiDEAQAgEV997vfNYwLCgpS6t5GPUUIAgDAglpaWnTgwAHD3PLly02qxhyEIAAALOi6666LmPvKV75iQiXmIQQBAGBB7777rmH89a9/3aRKzEMIAgDAYl588cWIuaP33rMSQhAAABZz++23G8aDBg1KqeecxQshCAAAC9m/f3/Eg8VXrVplUjXmIgQBAGAh1157rWFst9s1atQok6oxFyEIAACLCAaD2rJli2HuwQcfNKka8xGCAACwiLvvvjti7nvf+54JlSQHQhAAABbR/maIkydPNqmS5EAIAgDAAp599tmo5qyEEAQAgAXMmjXLMD7xxBMteVn8sQhBAACkubfffluBQMAw96c//cmkapIHIQgAgDR34403GsZer1eDBg0yqZrkQQgCACCNbd26VY2NjYY5q94csT1CEAAAaeyyyy4zjN1ut8aNG2dSNcmFEAQAQJras2eP6uvrDXOLFy82qZrkQwgCACBNtb8PkNPpjNgzZGWEIAAA0tCePXu0f/9+w9zSpUtNqiY5EYIAAEhDF154oWHsdDp16aWXmlRNciIEAQCQZrZt26ba2lrD3KJFi0yqJnkRggAASDMXX3yxYex0OnXllVeaVE3yIgQBAJBG3nnnnYj7Aj333HMmVZPcCEEAAKSRadOmGcYul0uTJk0yqZrkRggCACBNLFy4UD6fzzD3wgsvmFRN8iMEAQCQJmbPnm0Y5+bmauzYseYUkwIIQQAApIGysrKIuddff92ESlIHIQgAgBTX1NSk559/3jA3cuRInXTSSSZVlBoIQQAApLjzzjsvYu61114zoZLUQggCACCF/fWvf1V1dbVh7rrrrpPb7TapotRhC4VCIbOLSFb19fXKyMjo8fvYbDa53W75fD7xdUfH6XTK7/ebXUbKoMdiR49Fj/7qnkT1WJ8+fRQMBsNjm82m5ubmXv/ceIp3j0X7t9vZ409KYz6fL+JSw+5wOBxyu91qbGxUIBCIQ2XpLzs7Ww0NDWaXkTLosdjRY9Gjv7onET12//33GwKQdOQhqanW2/HusWhDEIfDAABIQQ0NDVq8eLFhrl+/frriiitMqij1EIIAAEhBp59+esTcX//6VxMqSV2EIAAAUszy5ctVX19vmCstLVW/fv1Mqig1EYIAAEghgUBAP/rRjwxzdrtdixYtMqmi1EUIAgAghZx11lkRc9wTqHsIQQAApIjnnnsu4p5A5557rrKk8qMAABbeSURBVE499VSTKkpthCAAAFKAz+fTnXfeaZiz2Wz67//+b5MqSn2EIAAAUsBpp50WMffSSy+ZUEn6IAQBAJDkHn30UdXW1hrmzj77bJ155pkmVZQeCEEAACSxffv26Re/+IVhzmaz6Y9//KNJFaUPQhAAAEmso8Ng5eXlJlSSfghBAAAkqa9//esRz9KaPn26vvSlL5lUUXohBAEAkIRWrVqlv/3tb4Y5r9erX/3qVyZVlH4IQQAAJJmamhrdcccdEfNbtmwxoZr0RQgCACDJdHQe0OrVq5WZmWlCNemLEAQAQBI566yzFAwGDXMXX3yxJk2aZFJF6YsQBABAkvjhD3+oyspKw5zX69Xvfvc7kypKb4QgAACSwCuvvKKVK1dGzG/bts2EaqyBEAQAgMl2796tG2+8MWL+7bffltPpNKEiayAEAQBgora2Np1xxhkR8w8++KBGjBhhQkXWQQgCAMBEw4cPj5ibMGGCZs6caUI11kIIAgDAJGPGjNHhw4cNc3l5eXr++edNqshaCEEAAJjgsssuU01NjWHO7XZzQ8QEIgQBAJBgM2fO1MaNGyPmd+zYIbudP82JwjcNAEAC/eQnP9GaNWsi5t9//33uCJ1ghCAAABLkl7/8pZ588smI+TVr1ujkk082oSJrIwQBAJAA69at089//vOI+Z/+9Ke64IILTKgIhCAAAHrZ+vXr9d3vfjdi/uabb9aMGTNMqAgSIQgAgF71wgsv6NZbb42Yv+SSSzrcM4TEIQQBANBLXnzxRd1yyy0R85dddpmWL19uQkU4FiEIAIBesGTJEn3729+OmJ8wYYKWLVtmQkVojxAEAECc/frXv9b3v//9iPkLLriAu0EnkZR4NO26dev01ltvaf/+/fJ4PJo4caKuv/56ORwOSdLhw4e1cOFC/f3vf1dWVpauvfZaXXLJJeGf37Vrl+bPn6+qqioVFhaqrKxMo0aNMmt1AABp7I477tCqVasi5q+44go9/fTTJlSE40mJEBQKhfSDH/xAJSUl+vzzzzVnzhz16dNHpaWlkqTFixcrEAho2bJl2rt3r37yk59o8ODBOvXUU+X3+zVnzhxNmTJFP/3pT/XOO+9o7ty5euqpp9S3b1+T1wwAkE6mTZumN998M2J+6tSpeuqpp0yoCJ1JicNhpaWlGjZsmJxOpwYMGKAJEyboo48+kiS1tLTo3Xff1fTp09WnTx+dfPLJuuCCC/T6669LkioqKtTa2qqpU6fK5XJp4sSJKigoUHl5uZmrBABIM1/96lc7DEAzZswgACWplNgT1N6WLVtUXFwsSfrss88kSUVFReHlQ4cO1fr16yVJ1dXVKi4uNjyLpaSkRNXV1RHvW1tbq9ra2vDYbrcrPz+/x/UePWx39L/RNZvNxvcVA3osdvRY9OivzgWDQRUXF6uxsTFi2f33368777zThKpSi1k9ZnoICgQCnS5v/4W8+OKLqqqq0g9/+ENJR/YEZWVlGV7j8XjU3NwsSWpubpbH44lY3tTUFPFZa9eu1ZIlS8Ljm266STNnzox+Zbrg9Xrj9l5W4Ha7zS4h5dBjsaHHYkN/Rdq3b58GDhyoUCgUsez5558Pn7aB6CS6x0wPQQ888IA2b97c4bJ+/fppxYoV4fFbb72l559/XnPmzAl/UZmZmeHAc1RjY2M4GGVlZUUEnqampojgJB057DZhwoTw2G63q66urnsrdgyHwyGv16v6+vouQx+O8Hg8Hf6rCh2jx2JHj0WP/urY//zP/+i6667rcNlf/vIXjRs3Li5/Q6wg3j2Wk5MT1etMD0Hz5s2L6nUbNmzQsmXL9Mgjj2jw4MHh+RNPPFGS9Omnn+qkk06SJFVWVoYPlxUVFWndunUKBoPhQ2KVlZWaMmVKxGfk5eUpLy8vPK6trY3rL3wgEGADEqVQKMR31Q30WPTosdjRX1+46667DP9IP8pms2n79u064YQT6LFuSHSPpcSJ0Rs2bNCSJUv04IMPhsPNUZmZmTrnnHO0cuVKNTU1qbKyUm+88YYuvPBCSdKYMWPkcrm0fv16tbW1acOGDaqpqdH48ePNWBUAQIo788wzOwxA2dnZqqmp0QknnGBCVegOW6ijA5lJZsaMGTp48KBcLld4buTIkZo9e7akI/cJWrBggf7+97+rT58+EfcJqqqq0oIFC1RVVaWCggKVlZVp9OjRXX7usSdJ94TD4VBOTo7q6ur4V0GUsrOz1dDQYHYZKYMeix09Fj3664iamhqddtppCgaDEctGjx6tt956yzBHj0Uv3j127FGdzqRECDILIcg8bDxiQ4/Fjh6LHv0lzZ49WwsXLuxw2V133aVZs2ZFzNNj0TMrBJl+ThAAAMkqGAxq3Lhxqqqq6nD566+/rtNOOy2xRSFuCEEAAHTg73//uy6++OIOl2VnZ+uTTz6R08mf0VSWEidGAwCQSN/4xjeOG4DOOuss7dy5kwCUBvh/EACA/2/Tpk3hq4s7snLlSl100UUJrAi9iRAEAICkCy64QBUVFR0uy83N1UcffcSjQ9IMh8MAAJb22muvKT8//7gB6N5779W2bdsIQGmIPUEAAEtqbGzU6aefrkOHDnW43OVyaevWrdz8MI2xJwgAYDnTpk3TkCFDjhuAbr31Vu3Zs4cAlObYEwQAsIz58+fr4YcfPu7y/Px8/d///Z/cbncCq4JZCEGwnLa2Nu3evVuVlZXauXOnduzYob1792rfvn2qr69XY2OjDh8+rLa2Nvl8PgUCASXqxuput1t9+vTRSSedpHPPPVfTp0/X8OHDE/LZQDp7+eWX9a1vfavT3+VVq1Zp8uTJCawKZiMEIan5/X7V1NRo+/btqqys1ObNm2W321VTU6OqqirV1tbK5/PJ5/Opra2tw2f6pJKj63Lo0CFVVFToySefNCzPz8/XzTffrDvuuMPwLD0AHXv//fdVWloqn8933NdMnjxZq1atSmBVSBY8O6wTPDssNj6fT3v27NGnn36q7du3a/fu3aqurlZ1dbXq6urU2NiolpYWtba2yu/3p3xgSQYnnHCCHn30UV1zzTWW6LF44rlO0UvFbdhf/vIXTZs2TX6//7ivGThwoDZu3KisrKxeqYEeix4PUE1C6RCCgsGg6uvr9a9//Ut79uxRdXW1Dhw4oL179+rgwYPav3+/Pv/8czU1NamtrU0tLS1qa2tTKBRSY2NjymzwIJWUlOixxx7TeeedZ3YpKYE/UNFLpRC0bNky3XPPPZ0e9srMzNSbb76pYcOG9Wot9Fj0eICqheTn54f/d1FRkYLBoCGABAKBcBA5iqzaexwOh1wul1wulzwej3JycuTxeDRo0CD1799fAwcO1EknnaShQ4dqwIAB6t+/vzIzM2Wz2eLy+YFAQHv27NEHH3yg8vJybdy4Ubt379bhw4dj2ltWWVmpq666SpI0bNgw/fGPf1T//v3jUiOQzEKhkO6880797ne/6/R1DodDK1eu7PSO0LAW9gR1ojf2BOXm5sblPa3IZrPJbrfrhBNOUF5enhwOhzIyMjR48GANGjRIJSUlGjFihIYMGaLCwsK0eq5PS0uLFixYoGeffVb79u2L+udsNpseeeQRffe73+3F6lIT/0qPXrLuCfrss8/09a9/XXv37u30dTabTcuWLdOll16aoMqOoMeix+GwJEQI6j673S6n0ym32y2Hw6E+ffooNzdXBQUFysvLU0lJiYYNG6ZRo0Zp0KBB6tOnj+Hn2Xh0benSpfr5z39+3PuctDdixAi99NJL8nq9vVxZaqDHopdMISgYDGrWrFlatmxZl6+12+1avny5pkyZkoDKItFj0SMEJaF0DUEOh0MOhyMcVFwuVzik5Obmyuv1asSIEXI6ncrJydGIESM0dOhQ5eTkJOzeGWw8YrNhwwZNnz5dLS0tXb7Wbrfr0Ucf1be+9a0EVJa86LHoJUMIeuqpp/TQQw91epXXUR6PR+vXr9fpp5+egMqOjx6LHiEoCfVGCJo8ebI++OCD8LITTzxROTk56tu3rzIyMtSnTx/l5eXJ5XIpLy9PgwcP1pAhQ5SVlaW8vDzl5uYqMzNTdnt63+ybjUdsjvbY559/runTp+vll1+O6ueGDBmiF198UQUFBb1cYfKhx6JnVgh6/vnndc8996i+vj6q15966qlat25d0tzlmR6LHidGW8Qrr7xidglIYzabTStWrJAkbdy4UdOmTVNjY+NxX19VVaXRo0dLkkpLS7Vw4UIeEgnTNDc360c/+pHWrVvX6aXtx7LZbLrzzjs1a9asXq4O6Si9dycAFjZu3DhVVVVp7969uuCCC7p8/dq1a1VYWKgBAwboRz/6kennfiD9BQIB/fa3v9WIESOUn5+voqIi/ed//mdUAWjIkCHatGmT9u/fTwBCtxGCgDTndDq1Zs0aHThwQOvXr484Cb29UCik5cuXhwPReeedp//93/9NULVIZx9//LGuvfZaDR48WPn5+SosLNQjjzyigwcPRvXzmZmZWrp0qQ4cOKC//vWvGjhwYC9XjHTH4TDAQs455xzt2rVLwWBQZWVlWrduXaevD4VC+vjjjw2XFmdlZWnkyJH61re+pauuukoZGRm9XTZSzPbt27Vy5Ur96U9/0qeffhr1oa2O5OXl6de//rUuvvjiOFYIHMGJ0Z1IhztGpypOKIxNT3ps9+7dKi0t1c6dO3upuvRz9MIEm80ml8sVvuGm0+lUZmZm+L9POOEE5efna8CAAerXr5+Kiork9XqVm5ur/v37Ky8vTyeccELSPwfu6PqVl5frww8/1Pvvv6+tW7dqz5494bvNx9Mpp5yip556SiNGjIjr+yYa27HocWI0AFMMHjxYGzdulCRt2bJF3/zmN1VdXW1yVcnt2Dt58w+bnhs0aJB+/OMfa/r06WaXAoshBAEIGzVqVPgWDs3Nzbrrrru0fv36uP9LH9aVkZGhU089VT/5yU909tlnm10OLI7DYZ3gcJh52I0cm0T0WDAY1Pr167Vw4UJt27ZNra2tvfI5SA9Op1ODBw/W+eefr+9///sqKioyu6SEYzsWPQ6HAUhqdrtdV111VfghrR1pbm7W/v37tX//fh06dEhut1sNDQ2y2+3KyMhQTk6OvF6vPB6PvF6vMjMzTbsvUbR/oPx+v5qamlRXV6dDhw5p3759qq+v12effaaDBw/q8OHDqq2t1eHDh3Xo0CE1NTWpoaFBra2t8vv9CgaDEf9J5X972u12uVwuZWZmKi8vT6effrouuugiTZ48WdnZ2WaXB8SEEAQgbrKyslRcXKzi4mKzS4kbp9Mpr9crr9ebtOsVDAbl9/vl9/vV1tYmv9+vUCgUPowZDAblcDhks9kUDAaVmZmpjIwMOZ1OOZ3OLu9Az95spCtCEACkOLvdLrfbnbBn+wHpgpslAgAASyIEAQAASyIEAQAASyIEAQAAS+I+QZ2or6+Py3ORbDab3G63fD5fSl8am0hOp7NHzxuyGnosdvRY9Oiv7qHHohfvHov2bzdXh3XC5/PJ5/P1+H0cDofcbrcaGxu5vDRK3GQsNvRY7Oix6NFf3UOPRS/ePRZtCOJwGAAAsCRCEAAAsCRCEAAAsCRCEAAAsCRCEAAAsCRCEAAAsCRCEAAAsCRulpgAtbW1Wrt2rUpLS5WXl2d2OUhD9Bh6E/2F3mZWj7EnKAFqa2u1ZMkS1dbWml0K0hQ9ht5Ef6G3mdVjhCAAAGBJhCAAAGBJjtmzZ882uwgryMrK0tixY9WnTx+zS0GaosfQm+gv9DYzeowTowEAgCVxOAwAAFgSIQgAAFiS0+wCUt2LL76oN998U1VVVRo/frx+/OMfh5ft2rVL8+fPV1VVlQoLC1VWVqZRo0aFl7/77rt69tlndejQIZ1yyim644471L9/fzNWA0mqs/6aMWOGDh06JLv9yL9l8vPztXDhwvBy+gvRaGtr06JFi/Thhx+qoaFBeXl5uuaaa3T++edLYjuGnumqv0zfjoXQI++++27ovffeCz355JOhRx99NDzf1tYWmjFjRuj5558P+Xy+0Jtvvhn693//91BDQ0MoFAqFPv3009C1114b+sc//hFqaWkJPfnkk6FZs2aZtRpIUsfrr1AoFLrllltCf/vb3zr8OfoL0Wpubg797ne/C+3duzcUCARCW7ZsCU2bNi20detWtmPosc76KxQyfzvG4bAe+upXv6qzzz5bXq/XMF9RUaHW1lZNnTpVLpdLEydOVEFBgcrLyyVJb731lv7t3/5Np59+ujIyMnTDDTfo448/1t69e81YDSSp4/VXV+gvRCszM1M33HCDCgsLZbfbNXLkSJ1yyinaunUr2zH0WGf91ZVE9BchqJdUV1eruLg4vItPkkpKSlRdXS3pyC7mkpKS8LLs7Gzl5+dr165dCa8VqevXv/61pk+frnvvvVcfffRReJ7+Qne1tLTon//8p4qLi9mOIe6O7a+jzNyOcU5QL2lubpbH4zHMeTweNTU1STrSCO3vheDxeNTc3JywGpHa7rzzTp188smSpDfeeEMPPfSQ5s+frwEDBtBf6JZQKKTf/OY3GjZsmM444wx98sknbMcQN+37SzJ/O8aeoF6SlZUV3lAc1dTUpKysLElHdhG2X97Y2BheDnRl5MiRysjIUEZGhi655BINHTpUH3zwgST6C7ELhUJ64okndPDgQd19992y2WxsxxA3HfWXZP52jBDUS4qKirRr1y4Fg8HwXGVlpYqKiiRJxcXFqqqqCi87fPiwamtrDbsIgVjY7XaF/v+9T+kvxCIUCmnRokXauXOnZs+erczMTElsxxAfx+uvjiR6O0YI6qFAICCfz6dgMKhgMCifzye/368xY8bI5XJp/fr1amtr04YNG1RTU6Px48dLks4//3x98MEH+vDDD9Xa2qqVK1fqy1/+sgYOHGjyGiGZHK+/Dhw4oC1btqitrU1tbW169dVXtX379vAuZvoLsVi8eLG2bdumhx56yHD4ge0Y4uF4/ZUM2zEem9FDq1at0u9//3vD3AUXXKAf/vCHqqqq0oIFC1RVVaWCggKVlZVp9OjR4de98847Wr58uerq6jRy5Ejur4EIx+uvq666So899pj27t0rp9Opk046SdOnT9eYMWPCr6O/EI39+/drxowZcrlccjgc4fmrr75a1157Ldsx9Ehn/XX22Webvh0jBAEAAEvicBgAALAkQhAAALAkQhAAALAkQhAAALAkQhAAALAkQhAAALAkQhAAALAkQhAAALAkQhAAALAkQhAAALAkQhAAALAkQhAAALAkQhCAtFBfX6/i4mJdc801hvnbb79dOTk52r17t0mVAUhWhCAAacHr9erZZ5/V2rVr9dxzz0mSXn31VT3xxBN64oknNHjwYJMrBJBsbKFQKGR2EQAQL3feeaeeeeYZ/fnPf9all16q8847T7///e/NLgtAEiIEAUgrLS0t+spXvqIdO3aof//+2rx5s3JycswuC0AS4nAYgLSSmZmpq666Sq2trbrhhhsIQACOiz1BANLK5s2bNXbsWI0cOVJbt27VBx98oJEjR5pdFoAkRAgCkDZ8Pp/GjRsnj8ejN998U+eee64CgYDef/99uVwus8sDkGQ4HAYgbTz44IPavn27li9fLrfbreeee05bt27Vww8/bHZpAJIQIQhAWigvL9ejjz6qxx57TCeffLIk6ctf/rIeffRR/fSnP9XGjRtNrhBAsuFwGAAAsCT2BAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEsiBAEAAEv6f0q1xkC6iPByAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (163516527771)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ggplot(map)+\\\n",
    "geom_point(aes(x='x',y='y'),size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \n",
    "    def __init__(self,state_size,action_size):\n",
    "        self.state_size=state_size\n",
    "        self.action_size=action_size\n",
    "        self.model = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
    "\n",
    "        self.target_update_counter = 0\n",
    "        #self.graph = tf.get_default_graph()\n",
    "\n",
    "        self.terminate = False\n",
    "        self.last_logged_episode = 0\n",
    "        self.training_initialized = False\n",
    "    \n",
    "    def get_weight(self):\n",
    "        \n",
    "        w = self.model.get_weights()        \n",
    "        return w\n",
    "    \n",
    "    def predict(self,state):\n",
    "        \n",
    "        predict = self.model.predict(state.reshape((1, self.state_size)))\n",
    "        return predict\n",
    "    \n",
    "    def save_model(self,name):\n",
    "        model_json = self.model.to_json()\n",
    "        with open(\"{}.json\".format(name), \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        self.model.save_weights(\"{}.h5\".format(name))\n",
    "        print(\"Saved model to disk\")     \n",
    "        \n",
    "\n",
    "    def create_model(self):\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Dense(4, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(32, input_dim=4, activation='relu')) \n",
    "        model.add(Dense(self.action_size, activation='sigmoid'))            # output nodes = #action\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=0.01))\n",
    "        return model\n",
    "\n",
    "    def update_replay_memory(self, transition):\n",
    "        # transition = (current_state, action, reward, new_state, done)\n",
    "        self.replay_memory.append(transition)\n",
    "\n",
    "    def train(self):\n",
    "        global Loss\n",
    "        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
    "            self.terminate=True\n",
    "            Loss.append(0)\n",
    "            return\n",
    "\n",
    "        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
    "        \n",
    "        current_states = np.array([transition[0] for transition in minibatch])\n",
    "        \n",
    "        #with self.graph.as_default():\n",
    "        current_qs_list = self.model.predict(current_states, PREDICTION_BATCH_SIZE)\n",
    "\n",
    "        new_current_states = np.array([transition[3] for transition in minibatch])\n",
    "        \n",
    "        #with self.graph.as_default():\n",
    "        future_qs_list = self.target_model.predict(new_current_states, PREDICTION_BATCH_SIZE)\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for index, (current_state, action, reward, new_state, done) in enumerate(minibatch):\n",
    "            if not done:\n",
    "                max_future_q = np.max(future_qs_list[index])\n",
    "                new_q = reward + DISCOUNT * max_future_q\n",
    "            else:\n",
    "                new_q = reward\n",
    "\n",
    "            current_qs = current_qs_list[index]\n",
    "            current_qs[action] = new_q\n",
    "            \n",
    "            X.append(current_state)\n",
    "            y.append(current_qs)\n",
    "\n",
    "\n",
    "        history=self.model.fit(np.array(X), np.array(y), batch_size=TRAINING_BATCH_SIZE, verbose=0, shuffle=False)\n",
    "        history\n",
    "        Loss.append(history.history['loss'][0])\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def get_qs(self, state):\n",
    "        return self.model.predict(state.reshape((1, self.state_size)))[0]\n",
    "        \n",
    "    def train_in_loop(self):\n",
    "        X = np.random.uniform(size=(1, self.state_size)).astype(np.float32)\n",
    "        y = np.random.uniform(size=(1, self.action_size)).astype(np.float32)\n",
    "        \n",
    "        self.model.fit(X,y, verbose=False, batch_size=1)\n",
    "\n",
    "        self.training_initialized = True\n",
    "        print('Start Train')\n",
    "        while True:\n",
    "            if self.terminate:\n",
    "                return\n",
    "            self.train()\n",
    "            time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent_load_model:\n",
    "    \n",
    "    def __init__(self,state_size,action_size,model):\n",
    "        self.state_size=state_size\n",
    "        self.action_size=action_size\n",
    "        self.model = self.loaded_model(model)\n",
    "        self.target_model = self.loaded_model(model)\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
    "\n",
    "        self.target_update_counter = 0\n",
    "        #self.graph = tf.get_default_graph()\n",
    "\n",
    "        self.terminate = False\n",
    "        self.last_logged_episode = 0\n",
    "        self.training_initialized = False\n",
    "        \n",
    "    def loaded_model(self,model):\n",
    "        \n",
    "        model.compile(loss='mse', optimizer=Adam(lr=0.01))\n",
    "        return model\n",
    "    \n",
    "    def get_weight(self):\n",
    "        \n",
    "        w = self.model.get_weights()        \n",
    "        return w\n",
    "    \n",
    "    def predict(self,state):\n",
    "        \n",
    "        predict = self.model.predict(state.reshape((1, self.state_size)))\n",
    "        return predict\n",
    "    \n",
    "    def save_model(self,name):\n",
    "        model_json = self.model.to_json()\n",
    "        with open(\"{}.json\".format(name), \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        self.model.save_weights(\"{}.h5\".format(name))\n",
    "        print(\"Saved model to disk\")     \n",
    "\n",
    "    def update_replay_memory(self, transition):\n",
    "        # transition = (current_state, action, reward, new_state, done)\n",
    "        self.replay_memory.append(transition)\n",
    "\n",
    "    def train(self):\n",
    "        global Loss\n",
    "        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
    "            self.terminate=True\n",
    "            Loss.append(0)\n",
    "            return\n",
    "\n",
    "        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
    "        \n",
    "        current_states = np.array([transition[0] for transition in minibatch])\n",
    "        \n",
    "        \n",
    "        #with self.graph.as_default():\n",
    "        current_qs_list = self.model.predict(current_states, PREDICTION_BATCH_SIZE)\n",
    "\n",
    "        new_current_states = np.array([transition[3] for transition in minibatch])\n",
    "        \n",
    "        #with self.graph.as_default():\n",
    "        future_qs_list = self.target_model.predict(new_current_states, PREDICTION_BATCH_SIZE)\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for index, (current_state, action, reward, new_state, done) in enumerate(minibatch):\n",
    "            if not done:\n",
    "                max_future_q = np.max(future_qs_list[index])\n",
    "                new_q = reward + DISCOUNT * max_future_q\n",
    "            else:\n",
    "                new_q = reward\n",
    "\n",
    "            current_qs = current_qs_list[index]\n",
    "            current_qs[action] = new_q\n",
    "            \n",
    "            X.append(current_state)\n",
    "            y.append(current_qs)\n",
    "\n",
    "\n",
    "        history=self.model.fit(np.array(X), np.array(y), batch_size=TRAINING_BATCH_SIZE, verbose=0, shuffle=False)\n",
    "        history\n",
    "        Loss.append(history.history['loss'][0])\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def get_qs(self, state):\n",
    "        return self.model.predict(state.reshape((1, self.state_size)))[0]\n",
    "        \n",
    "    def train_in_loop(self):\n",
    "        X = np.random.uniform(size=(1, self.state_size)).astype(np.float32)\n",
    "        y = np.random.uniform(size=(1, self.action_size)).astype(np.float32)\n",
    "        \n",
    "        self.model.fit(X,y, verbose=False, batch_size=1)\n",
    "\n",
    "        self.training_initialized = True\n",
    "        print('Start Train')\n",
    "        while True:\n",
    "            if self.terminate:\n",
    "                return\n",
    "            self.train()\n",
    "            time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECONDS_PER_EPISODE = 100\n",
    "REPLAY_MEMORY_SIZE = 5_000\n",
    "MIN_REPLAY_MEMORY_SIZE = 32\n",
    "MINIBATCH_SIZE = 32\n",
    "PREDICTION_BATCH_SIZE = 1\n",
    "TRAINING_BATCH_SIZE = MINIBATCH_SIZE // 4\n",
    "UPDATE_TARGET_EVERY = 5\n",
    "\n",
    "\n",
    "MEMORY_FRACTION = 0.4\n",
    "MIN_REWARD = -200\n",
    "\n",
    "EPISODES = 32000\n",
    "\n",
    "DISCOUNT = 0.99\n",
    "epsilon = 1\n",
    "EPSILON_DECAY = 0.99975 ## 0.9975 99975\n",
    "MIN_EPSILON = 0.001\n",
    "\n",
    "AGGREGATE_STATS_EVERY = 10\n",
    "state_size=4\n",
    "action_size=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW model or LOAD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    json_file = open('DATA\\\\{}.json'.format(model_name), 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"DATA\\\\{}.h5\".format(model_name))\n",
    "    \n",
    "    print(\"Loaded model from disk\")\n",
    "    loaded_model.summary()\n",
    "    \n",
    "    file_path=\"DATA\\\\\"\n",
    "    df=pd.read_csv(file_path+'{}.csv'.format(model_name))\n",
    "    episode = df.Episode.tail(1).values[0]+1\n",
    "    epsilon = df.Epsilon.tail(1).values[0]\n",
    "    print('Episode : {} , Epsilon : {} '.format(episode,epsilon))\n",
    "    \n",
    "    return df,episode,epsilon,loaded_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_every_5k(name,n):\n",
    "    file_path=\"DATA\\\\\"\n",
    "    df.to_csv(file_path+'{}_{}.csv'.format(name,n))\n",
    "    agent.save_model(file_path+name+'_'+str(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD = False\n",
    "model_name='backup\\Steer_Full_2_040520_2130'\n",
    "if LOAD == True :\n",
    "    df_load,load_episode,load_epsilon,loaded_model = load_model(model_name)\n",
    "    value=['Episode','Reward','avg_reward','Step','Loss','avg_loss','Steer','Explore','PCT_Explore','Epsilon']\n",
    "    df_load=df_load[value]\n",
    "    df_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_load.plot.scatter('Episode','avg_reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a02c89533544a183ba88b19d12b79c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode :0, Step :19, Epsilon :0.09997500000000001 ,Reward :41.80062053921286, Explore_rate :0.21052631578947367, loss :0 ,Steer :0.19999999999999998\n",
      "Saved model to disk\n",
      "Episode :1, Step :20, Epsilon :0.09995000625000001 ,Reward :41.88063263625531, Explore_rate :0.1, loss :0 ,Steer :0.185\n",
      "Episode :2, Step :21, Epsilon :0.09992501874843751 ,Reward :42.968659898606134, Explore_rate :0.047619047619047616, loss :1.3451444804668427 ,Steer :0.18095238095238098\n",
      "Episode :3, Step :20, Epsilon :0.0999000374937504 ,Reward :40.70402518059964, Explore_rate :0.0, loss :1.2347746193408966 ,Steer :0.205\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-056589d98a1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m                     \u001b[1;31m#new_state,reward,done,_= env.test_step(steer,sleepy)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                     \u001b[0mnew_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m                     \u001b[1;31m#steer_+=steer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mFPS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-b1540900d8cd>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_control\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcarla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVehicleControl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthrottle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbrake\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msleepy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m             \u001b[0msteer_\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_reward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    \n",
    "    if carla_is_running():\n",
    "        pass\n",
    "    else:\n",
    "        close_carla()\n",
    "        open_carla('not fast')\n",
    "        time.sleep(17)\n",
    "    #open_carla('fast')\n",
    "    FPS=60\n",
    "    town='town03'\n",
    "    ep_rewards = []\n",
    "    ep=[]\n",
    "    avg=0\n",
    "    av_loss=0\n",
    "    avg_loss=[]\n",
    "    avg_reward=[]\n",
    "    Step=[]\n",
    "    Loss=[]\n",
    "    Explore=[]\n",
    "    Steer=[]\n",
    "    Epsilon=[]\n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "    steer_amt=0.3\n",
    "    sleepy=0.3\n",
    "\n",
    "    #pp = ProgressPlot(x_label=\"Episode\",line_names=['Average_reward'])\n",
    "    \n",
    "    if LOAD == True:\n",
    "    # In case Train from loaded_model\n",
    "        agent=DQNAgent_load_model(state_size,action_size,loaded_model)\n",
    "        epsilon=load_epsilon\n",
    "        nn=0\n",
    "        for i in df_load.Reward:\n",
    "            avg=((avg*(nn)+i)/(nn+1))\n",
    "            #pp.update(float(avg))\n",
    "            nn+=1\n",
    "        avg=sum(df_load.Reward)/df_load.shape[0]\n",
    "        av_loss=sum(df_load.Loss)/df_load.shape[0]\n",
    "    else :\n",
    "        \n",
    "    # Create agent and environment\n",
    "        agent = DQNAgent(state_size,action_size)\n",
    "        load_episode=0\n",
    "    \n",
    "    env = CarEnv()\n",
    "    #env.Black_screen()\n",
    "    xxx()\n",
    "    \n",
    "    agent.train_in_loop()\n",
    "    agent.get_qs(np.ones((1, state_size)))\n",
    "    \n",
    "    ## Re_epsilon\n",
    "    epsilon = 0.1\n",
    "\n",
    "    # Iterate over episodes\n",
    "    with tqdm(total=EPISODES-load_episode) as pbar:\n",
    "        \n",
    "        for episode in range(EPISODES-load_episode):            \n",
    "            #try:\n",
    "\n",
    "            env.collision_hist = []\n",
    "            episode_reward = 0\n",
    "            loss=0\n",
    "            step = 1\n",
    "            explore=0\n",
    "            steer_=0\n",
    "\n",
    "            # Reset environment and get initial state\n",
    "            current_state = env.reset()\n",
    "\n",
    "            # Reset flag and start iterating until episode ends\n",
    "            done = False\n",
    "            episode_start = time.time()\n",
    "\n",
    "            # Play for given number of seconds only\n",
    "            while True:\n",
    "\n",
    "                # This part stays mostly the same, the change is to query a model for Q values\n",
    "                rand=np.random.random()\n",
    "                if rand > epsilon:\n",
    "                    # Get action from Q table\n",
    "                    action = np.argmax(agent.get_qs(current_state))\n",
    "                    #action=loaded_model.predict(state)\n",
    "                    #a=agent.get_qs(current_state)\n",
    "                    \n",
    "                    #a1=a[0]/a.sum()\n",
    "                    #a2=a[1]/a.sum()            \n",
    "                    #steer=(-steer_amt*a1)+(steer_amt*a2)\n",
    "                    #new_state,reward,done,_= env.test_step(steer,sleepy)\n",
    "                    \n",
    "                    new_state, reward, done, _ = env.step(action)\n",
    "                    #steer_+=steer\n",
    "                    time.sleep(1/FPS)\n",
    "                    \n",
    "                else:\n",
    "                    # Get random action\n",
    "                    action = np.random.randint(0, action_size)\n",
    "                    new_state, reward, done, _ = env.step(action)\n",
    "                    explore+=1\n",
    "                    \n",
    "                    #if action==0:\n",
    "                        #steer_+=steer_amt\n",
    "                    #else :\n",
    "                        #steer_-=steer_amt\n",
    "                    \n",
    "            \n",
    "                    # This takes no time, so we add a delay matching 60 FPS (prediction above takes longer)\n",
    "                    time.sleep(1/FPS)\n",
    "             \n",
    "                # Every step we update replay memory\n",
    "                episode_reward += reward\n",
    "              \n",
    "                agent.update_replay_memory((current_state, action, reward, new_state, done))\n",
    "                current_state = new_state\n",
    "                step += 1\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "                    \n",
    "            # End of episode - destroy agents\n",
    "            for actor in env.actor_list:\n",
    "                actor.destroy()\n",
    "            agent.train()\n",
    "            \n",
    "            # Decay epsilon\n",
    "            if epsilon > MIN_EPSILON:\n",
    "                epsilon *= EPSILON_DECAY\n",
    "                epsilon = max(MIN_EPSILON, epsilon)\n",
    "                \n",
    "            print('Episode :{}, Step :{}, Epsilon :{} ,Reward :{}, Explore_rate :{}, loss :{} ,Steer :{}'\\\n",
    "                  .format(episode+load_episode,step,epsilon,episode_reward,explore/step,Loss[episode],steer_/step))\n",
    "            \n",
    "            ep_rewards.append(episode_reward)\n",
    "            ep.append(episode+load_episode)\n",
    "            Step.append(step)\n",
    "            Explore.append(explore)\n",
    "            Steer.append(steer_/step)\n",
    "            Epsilon.append(epsilon)\n",
    "            avg=((avg*(episode+load_episode)+episode_reward)/(episode+load_episode+1))\n",
    "            avg_reward.append(avg)\n",
    "            av_loss=((av_loss*(episode+load_episode)+Loss[episode])/(episode+load_episode+1))\n",
    "            avg_loss.append(av_loss)\n",
    "            #pp.update(float(avg))  \n",
    "            \n",
    "            if (episode+load_episode) %5000 ==0 :\n",
    "                df=pd.DataFrame({'Episode':ep,'Reward':ep_rewards,\\\n",
    "                 'avg_reward':avg_reward,'Step':Step,'Loss':Loss[1:],\\\n",
    "                 'avg_loss':avg_loss,\\\n",
    "                'Steer':Steer,'Explore':Explore,'PCT_Explore':np.array(Explore)/np.array(Step)*100\\\n",
    "                ,'Epsilon':Epsilon})\n",
    "                if LOAD == True:\n",
    "                    df=pd.concat([df_load,df],ignore_index=True)\n",
    "                save_every_5k(model_name,episode+load_episode)\n",
    "            \n",
    "            \n",
    "            #pbar.update(1)\n",
    "    close_carla()\n",
    "    pp.finalize()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Episode':ep,'Reward':ep_rewards,\\\n",
    "                 'avg_reward':avg_reward,'Step':Step,'Loss':Loss[1:],\\\n",
    "                 'avg_loss':avg_loss,\\\n",
    "                'Steer':Steer,'Explore':Explore,'PCT_Explore':np.array(Explore)/np.array(Step)*100\\\n",
    "                ,'Epsilon':Epsilon})\n",
    "if LOAD == True:\n",
    "    df=pd.concat([df_load,df],ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('DATA\\Steer_Full_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df.iloc[:12500],aes(x='Reward'))+\\\n",
    "geom_histogram(binwidth=0.5,fill='#48b6a3')+\\\n",
    "xlim(-10,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[12500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df[:12500], aes(x='Episode',y='Reward'))+ \\\n",
    "  geom_point(color=\"#F18F01\", size=0.2)+\\\n",
    "    geom_smooth(method=\"lm\", se=False, size=0.5, linetype=\"dashed\")+\\\n",
    "        ylim(-10,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df, aes(x='Episode',y='Step'))+ \\\n",
    "    geom_line(size=0.05,alpha=0.8) +\\\n",
    "    stat_smooth(colour='blue', span=0.2)+\\\n",
    "        ylim(0,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "c=0\n",
    "xx=[]\n",
    "yy=[]\n",
    "for i in df['Reward']:\n",
    "    n+=i\n",
    "    c+=1\n",
    "    if c%100==0:\n",
    "        xx.append(n/100)\n",
    "        n=0\n",
    "n=0\n",
    "c=0\n",
    "for i in df['Step']:\n",
    "    n+=i\n",
    "    c+=1\n",
    "    if c%100==0:\n",
    "        yy.append(n/100)\n",
    "        n=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Reward']>20].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df[df['Reward']>20])+\\\n",
    "geom_density(aes(x='PCT_Explore'),color='midnightblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df__=pd.DataFrame({'reward':xx,'avg_every_100ep':[i for i in range(len(xx))],'step':yy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df__['reward/step']=df__['reward']/df__['step']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df, aes(x='Episode',y='avg_reward'))+ \\\n",
    "    geom_line(size=0.6,alpha=0.5) +\\\n",
    "    stat_smooth(colour='blue', span=0.2,linetype='dashed')+\\\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df__)+\\\n",
    "geom_line(aes(y='reward/step',x='avg_every_100ep'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df__, aes(x='avg_every_100ep',y='reward'))+ \\\n",
    "    geom_line(size=0.6,alpha=0.5) +\\\n",
    "    stat_smooth(colour='blue', span=0.2,linetype='dashed')+\\\n",
    "theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df, aes(x='Episode',y='avg_reward'))+ \\\n",
    "    geom_line(size=0.7,color='seagreen') +\\\n",
    "    stat_smooth(colour='blue', span=0.3,size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df, aes(x='Episode',y='Step'))+ \\\n",
    "  geom_point(color=\"#F18F01\", size=0.2)+\\\n",
    "    geom_smooth(method=\"lm\", se=False, size=0.5, linetype=\"dashed\")+\\\n",
    "        ylim(0,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df.iloc[10000:], aes(x='Episode',y='Steer'))+ \\\n",
    "  geom_point(color=\"#F18F01\", size=0.2) +\\\n",
    "    geom_smooth(method=\"lm\", se=False, size=0.5, linetype=\"dashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df, aes(x='Episode',y='Loss'))+ \\\n",
    "  geom_line(size=0.01,color='mediumblue') +\\\n",
    "    geom_smooth(method=\"lm\",color='firebrick', se=False, size=0.5, linetype=\"dashed\")+\\\n",
    "ylim(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df, aes(x='Episode',y='avg_loss'))+ \\\n",
    "  geom_point(color='midnightblue',size=0.05) +\\\n",
    "    geom_smooth(method=\"lm\", se=False, size=0.5, linetype=\"dashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ggplot(df.iloc[:12500], aes(x='Episode',y='PCT_Explore'))+ \\\n",
    "  geom_point(color='midnightblue',size=0.05) +\\\n",
    "    geom_smooth( size=1, linetype=\"dashed\")+\\\n",
    "theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='Steer_Full_video' ##INSERT FILE NAME\n",
    "n = datetime.datetime.now()\n",
    "n = n.strftime('_%m%d%y_%H%M')\n",
    "\n",
    "##real\n",
    "file_path=\"DATA\\\\\"\n",
    "df.to_csv(file_path+'{}.csv'.format(name))\n",
    "agent.save_model(file_path+name)\n",
    "##backup\n",
    "name=name+n\n",
    "file_path_backup=\"DATA\\\\backup\\\\\"\n",
    "df.to_csv(file_path_backup+'{}.csv'.format(name))\n",
    "agent.save_model(file_path_backup+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model for Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='backup\\Steer_Full_2_040520_2130'\n",
    "\n",
    "json_file = open('DATA\\\\{}.json'.format(model_name), 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"DATA\\\\{}.h5\".format(model_name))\n",
    "print(\"Loaded model from disk\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if carla_is_running():\n",
    "    print('carla is running')\n",
    "else:\n",
    "    close_carla()\n",
    "    open_carla('not fast')\n",
    "    time.sleep(17)\n",
    "\n",
    "town='town03'\n",
    "test_ep=10\n",
    "test_step=[]\n",
    "test_reward=[]\n",
    "test_action=[]\n",
    "test_steer=[]\n",
    "steer_amt=0.3\n",
    "env=CarEnv()\n",
    "sleepy=0.1\n",
    "map_save=[]\n",
    "dist_average=[]\n",
    "dist=[]\n",
    "time_=[]\n",
    "finish=[]\n",
    "state_size=loaded_model.input.shape[1]\n",
    "action_size=loaded_model.output.shape[1]\n",
    "print('State size = {} // Action size = {} '.format(state_size,action_size))\n",
    "\n",
    "\n",
    "with tqdm(total=test_ep) as pbar:\n",
    "    for episode in range(test_ep):\n",
    "        state=env.reset()\n",
    "        map_=[]\n",
    "        dist_=[]\n",
    "        action_=[]\n",
    "        done = False\n",
    "        step=0\n",
    "        rewards=0\n",
    "        steer_=0\n",
    "        \n",
    "        while True:\n",
    "            step+=1\n",
    "            state=np.array([[i for i in state]])\n",
    "            action=np.argmax(loaded_model.predict(state))\n",
    "            map_.append(env.get_location())\n",
    "            dist_.append(env.get_distance())\n",
    "            action_.append(action)\n",
    "            time.sleep(0.01)\n",
    "            state,reward,done,_=env.step(action)\n",
    "            rewards+=reward\n",
    "            \n",
    "    \n",
    "            if done:\n",
    "                finish.append(False)\n",
    "                break\n",
    "            #if step == 260:\n",
    "                #print('SUCCESS')\n",
    "                #finish.append(True)\n",
    "                #break\n",
    "            \n",
    "        for actor in env.actor_list:\n",
    "                actor.destroy()\n",
    "                \n",
    "        dist_average.append(np.sum(dist_)/len(dist_))\n",
    "        map_save.append(map_)\n",
    "        test_action.append(action_)\n",
    "        test_reward.append(rewards)\n",
    "        test_step.append(step)\n",
    "        test_steer.append(steer_/step)\n",
    "        \n",
    "        pbar.update(1)\n",
    "close_carla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.DataFrame({'Episode':[i for i in range(len(test_step))],\\\n",
    "                      'Step':test_step,'Reward':test_reward,\\\n",
    "                    'Steer':test_steer,'Dist':dist_average,'Finish':finish})\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAP Observation\n",
    "epi_test=5\n",
    "map_create=pd.DataFrame({'X':np.array(map_save[epi_test])[:,0],'Y':np.array(map_save[epi_test])[:,1]})\n",
    "mp=pd.concat([map.iloc[1:1400],map_create],axis=1)\n",
    "\n",
    "##PLOT\n",
    "ggplot(mp)+\\\n",
    "geom_point(aes(x='x',y='y'),size=0.3,color='firebrick')+\\\n",
    "geom_point(aes(x='X',y='Y'),size=0.7)+\\\n",
    "theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(map.iloc[:1300])+\\\n",
    "geom_point(aes(x='x',y='y'),size=0.3,color='firebrick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_test, aes(x='Episode',y='Reward'))+ \\\n",
    "  geom_line(color=\"#F18F01\", size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(df_test, aes(x='Episode',y='Step'))+ \\\n",
    "  geom_point(color=\"#F18F01\", size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_carla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "KWY Contents",
   "title_sidebar": "KWY Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "199px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
